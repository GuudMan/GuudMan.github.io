<!DOCTYPE html><html lang="zh-cn" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Ai4Future</title><meta name="keywords" content="成长，分享，专注"><meta name="author" content="AI4Future"><meta name="copyright" content="AI4Future"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Not Only Look Once">
<meta property="og:type" content="website">
<meta property="og:title" content="Ai4Future">
<meta property="og:url" content="https://guudman.github.io/page/3/index.html">
<meta property="og:site_name" content="Ai4Future">
<meta property="og:description" content="Not Only Look Once">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://guudman.github.io/img/avatar.jpg">
<meta property="article:author" content="AI4Future">
<meta property="article:tag" content="成长，分享，专注">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://guudman.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://guudman.github.io/page/3/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":50,"languages":{"author":"Author: AI4Future","link":"Link: ","source":"Source: Ai4Future","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://fastly.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://fastly.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Ai4Future',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-12-02 16:07:11'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Ai4Future" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="onerror=null;src='https://gitee.com/guudman/blog_images/raw/master/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">AI4Future</div><div class="author-info__description">Not Only Look Once</div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/GuudMan" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2663017379@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-clock"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/gedan"><i class="fa-fw fas fa-music"></i><span> 歌单</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk"><i class="fa-fw fa fa-heartbeat"></i><span> 时光</span></a></div><div class="menus_item"><a class="site-page" href="/shuoba"><i class="fa-fw fas fa-comment-dots"></i><span> 说吧</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/google"><span> 镜像</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://json.xbyzs.cf"><span> Json格式化</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://draw.xbyzs.cf"><span> Draw画布</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://enkey.xbyzs.cf"><span> EnKey</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ai4Future</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-clock"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/gedan"><i class="fa-fw fas fa-music"></i><span> 歌单</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk"><i class="fa-fw fa fa-heartbeat"></i><span> 时光</span></a></div><div class="menus_item"><a class="site-page" href="/shuoba"><i class="fa-fw fas fa-comment-dots"></i><span> 说吧</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/google"><span> 镜像</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://json.xbyzs.cf"><span> Json格式化</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://draw.xbyzs.cf"><span> Draw画布</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://enkey.xbyzs.cf"><span> EnKey</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/04/MobileNet/" title="MobileNet">MobileNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-04T01:32:47.000Z" title="Created 2023-11-04 09:32:47">2023-11-04</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:05:44.825Z" title="Updated 2023-11-29 18:05:44">2023-11-29</time></span></div><div class="content">

1、简介在之前的文章中讲的AlexNet， VGG， GoogleNet以及ResNet网络， 它们都是传统卷积神经网络（都是使用传统卷积层），缺点是内存需求大、运算量大而导致无法在移动设备以及嵌入式设备上运行， 这里要讲的MobileNet网络就是专门为移动端，嵌入式端而设计的。
1、MobileNetv1MobileNet模型是Google在2017年针对手机或嵌入式提出的轻量级模型， 专注于移动端或嵌入式设备中的轻量级CNN网络。相比于传统卷积神经网络， 在准确率小幅度降低的前提下大大减少模型参数与运算量。(相比VGG16准确率减少了0.9%,但模型参数只有VGG的1/32)
要说MobileNet网络的优点， 无疑是其中的Depthwise  Convolution结构（大大减少了运算量和参数数量)。下图展示了传统卷积与DW卷积的差异。在传统卷积中， 每个卷积核的channel与输入特征矩阵的channel相等(每个卷积核都会与输入特征矩阵的每一个维度进行卷积运算)。 
而在DW卷积中， 每个卷积核的channel都是等于1的(每个卷积核只负责输入特征矩阵的一个channe ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/04/ResNet/" title="ResNet">ResNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-04T01:27:40.000Z" title="Created 2023-11-04 09:27:40">2023-11-04</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:06:00.642Z" title="Updated 2023-11-29 18:06:00">2023-11-29</time></span></div><div class="content">

1、简介Resnet由微软实验室于2015年提出， 获得当年ImageNet竞赛分类任务第一名， 目标检测第一名。获得COCO数据集目标检测第一名， 图像分割第一名。
下图是ResNet34的简图。

网络的亮点

超深的网络结构(突破1000层)

提出residual模块(残差结构)

使用batch normalization加速训练(放弃使用dropout)


在ResNet网络提出之前， 传统的卷积神经网络都是通过一系列卷积层与下采样层进行堆叠得到的， 但是当网络堆叠到一定网络深度时， 就会出现如下两个问题：

梯度消失或梯度爆炸
退化问题(degradation problem)

在ResNet论文中说通过数据的预处理以及在网络中使用BN(batch normalization)层能够解决梯度消失或者梯度爆炸问题。但是对于退化问题（随着网络层数的加深， 效果还会变差）并无很好的解决方法。

所以ResNet论文提出了residual结构(残差结构)来减轻退化问题。下图是使用residual结构的卷积网络， 可以看到随着网络的不断加深， 效果并没有变差，反而变得更好了 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/04/BatchNormalization/" title="BatchNormalization">BatchNormalization</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-04T01:22:37.000Z" title="Created 2023-11-04 09:22:37">2023-11-04</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:04:57.687Z" title="Updated 2023-11-29 18:04:57">2023-11-29</time></span></div><div class="content">

1、简介BatchNormalization原文： BN原论文)
Batch Normalization是google团队在2015年提出的， 该方法能够加速网络的收敛并提高准确率。

本文分为以下几个部分：

BN的原理
使用pytorch验证本文观点
BN使用注意事项

2、Batch Normalization原理在图像预处理中通常会对图像进行标准化处理， 这样能够加速网络的收敛， 对于Conv1来说， 输入就是满足某一分布的特征矩阵， 但是对Conv2而言的feature map就不一定满足某一分布规律了(注意这里所说的满足某一分布规律并不是指某一个feature map的数据要满足分布规律， 理论上指整个训练样本集所对应的feature map的数据要满足分布规律)。而我们的Batch Normalization的目的就是使我们的feature map满足均值为0，方差为1的分布规律。

下面是从原论文中截取的原话

对于一个拥有d维的输入x， 我们将对它的每一个维度进行标准化处理， 假设我们输入的x是RGB三通道的彩色图像，这里的d就是输入图像的channels即d=3 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%8D%B7%E7%A7%AF/" title="深度学习中的卷积">深度学习中的卷积</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-02T12:07:13.000Z" title="Created 2023-11-02 20:07:13">2023-11-02</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-04T07:08:11.984Z" title="Updated 2023-11-04 15:08:11">2023-11-04</time></span></div><div class="content">

深度学习中什么是卷积， 它是如何工作的1、数学物理层面数学上，连续卷积的定义如下：
(f  g)(t) = ∫[f(τ)  g(t - τ)] dτ
其中， 表示卷积操作，f(t) 和 g(t) 是两个函数，(f  g)(t) 是它们的卷积结果。
它的物理含义可以理解为：系统某一时刻的输出是由多个输入共同作用（叠加）的结果。
具体解释如下：
假设有两个物理量（例如信号，场或系统响应等），可用公式中的函数f(t) 和 g(t)表示。在物理上，卷积大概可以理解为：系统某一时刻的输出是由多个输入共同作用(叠加)的结果。
g(t) 是系统的响应函数（或滤波器）。它描述了系统对输入信号 f(t) 的响应方式。g(t) 中的每一个值表示了在时间 t 时，系统对输入信号的加权响应。
在卷积过程中，我们考虑了 f(t) 中的每个时间点 τ，并将其与 g(t - τ) 相乘。这相当于在时间轴上对 g(t - τ) 进行了平移，然后与 f(t) 相乘。这个过程捕捉了在不同时间点上，系统响应函数 g(t) 对输入信号 f(t) 的影响。
最后，通过对所有时间点的乘积进行积分，我们将所有加权的响应值进行累 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/02/pytorch%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E6%A8%A1%E6%8B%9F%E5%9B%9E%E5%BD%92/" title="pytorch全连接层模拟回归">pytorch全连接层模拟回归</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-02T11:58:58.000Z" title="Created 2023-11-02 19:58:58">2023-11-02</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-04T07:08:35.428Z" title="Updated 2023-11-04 15:08:35">2023-11-04</time></span></div><div class="content">

实现过程搭建两层全连接网络
12345678910class Net(torch.nn.Module):    def __init__(self, n_feature, n_hidden, n_output):        super(Net, self).__init__()        self.hidden = torch.nn.Linear(n_feature, n_hidden)        self.predict = torch.nn.Linear(n_hidden, n_output)    def forward(self, x):        x = F.relu(self.hidden(x))        x = self.predict(x)        return x
预测的值画成曲线
123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/02/GoogleNet%E8%A7%A3%E6%9E%90/" title="GoogleNet解析">GoogleNet解析</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-02T11:37:32.000Z" title="Created 2023-11-02 19:37:32">2023-11-02</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:05:26.093Z" title="Updated 2023-11-29 18:05:26">2023-11-29</time></span></div><div class="content">

1、简介GoogleNet在2014年由Google团队提出，斩获当年ImageNet竞赛中Classification Task分类任务第一名。
论文原文： GoogleNet原文)

首先介绍一下该网络的亮点：

引入Inception结构(融合不同尺度的特征信息)

使用1×1的卷积核进行降维以及映射处理

添加两个辅助分类器帮助训练

丢弃全连接层，使用平均池化层(大大减少模型参数, 除去两个辅助分类器， 网络大小只有vgg的1/20)


接着分析一下Inception结构：

​    左图是论文中提出的inception原始结构， 右图是inception加上降维功能的结构。
先看左图， inception一共有4个分支， 也就是说输入的特征矩阵并行通过这个4个分支得到四个输出， 然后在将这个四个输出在深度维度(channel维度)进行拼接得到最终的输出(注意：为了让四个分支的输出能够在深度方向进行拼接， 必须保证四个分支输出的特征矩阵高度和宽度都相同)
分支1是卷积核大小为1×1的卷积层， stride=1
分支2是卷积核大小为3×3的卷积层， stride=1，  ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/02/VggNet%E8%A7%A3%E6%9E%90/" title="VggNet解析">VggNet解析</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-02T11:17:44.000Z" title="Created 2023-11-02 19:17:44">2023-11-02</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:06:28.935Z" title="Updated 2023-11-29 18:06:28">2023-11-29</time></span></div><div class="content">

1、简介论文原文： VggNet原文](https://arxiv.org/pdf/1409.1556.pdf))
VGG由牛津大学视觉几何小组(Visual Geometry Group, VGG)提出的一种深层卷积网， 该网络在2014年获得定位任务的第一名， 分类任务的第二名。VGG可以看成是加深版的AlexNet， 都是conv + FC layer组成。
下图是VGG16模型的结构简图

网络的亮点

通过堆叠多个3×3的卷积代替大尺度卷积核 (在保证相同感受野的前提下能够减少所需的参数量)

论文中提到，通过堆叠两个3×3的卷积核代替5×5的卷积核， 堆叠三个3×3的卷积核代替7×7的卷积核。It is easy to see that a stack of two 3 × 3 conv layers (without spatial pooling in between) has an effective receptive field of 5 × 5; three such layers have a 7 × 7 effective receptive field ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/02/AlexNet%E8%A7%A3%E6%9E%90/" title="AlexNet解析">AlexNet解析</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-02T11:11:45.000Z" title="Created 2023-11-02 19:11:45">2023-11-02</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:04:48.784Z" title="Updated 2023-11-29 18:04:48">2023-11-29</time></span></div><div class="content">

1、AlexNet简介Alexnet是2012年ILSVRC 2012(ImageNet Large Scale Visual Recognition Challenge)竞赛的冠军网络， 分类准确率由传统的70%提升到80%(当时传统方法已进入瓶颈期，所以这么大的提升是非常厉害的)。它是由Hinton和他的学生Alex设计的。也是在那年之后，深度学习模型开始迅速发展。下面的图就是Alexnet原论文中截取的网络结构图。
Alexnet论文原文， AlexNet

图中有上下两部分是因为作者使用两块GPU进行并行训练， 所以上下两部分的结果是一模一样的。我们直接看下面部分就行了。
接着说说该网络的亮点：
(1)首次使用了GPU进行网络加速训练
(2)使用了ReLU激活函数， 而不是传统的Sigmoid激活函数以及Tanh激活函数
(3)使用了LRN局部相应归一化
(4)在全连接层的前两层使用了Dropout方法按照一定比例随机失活神经元，以减少过拟合
接着给出卷积或池化后的矩阵尺寸大小计算公式
N = (W - F  + 2p)/s + 1
其中w是输入图片大小， F是 卷积核或池 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/10/11/scipy%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="scipy中常用的数据结构">scipy中常用的数据结构</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-10-11T07:28:31.000Z" title="Created 2023-10-11 15:28:31">2023-10-11</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:06:08.896Z" title="Updated 2023-11-29 18:06:08">2023-11-29</time></span></div><div class="content">

1、 scipy中常用的数据结构1.1 scipy.sparse.coo_matrixcoo_matrix全称是A sparse matrix in Coordinate format， 一种基于坐标格式的系数矩阵， 每个矩阵时一个三元组（行， 列， 值）
构造方法如下：
12345678910111213141516171819202122232425262728293031323334import numpy as npfrom scipy.sparse import coo_matrixcoo = coo_matrix(np.array([1, 0, 3, 0, 5, 6]).reshape(2, 3))print(coo)&quot;&quot;&quot;  (0, 0)	1  (0, 1)	2  (0, 2)	3  (1, 0)	4  (1, 1)	5  (1, 2)	6  coo_matrix中值表示非零元素， 如果该位置是0， 则没有改行的数值  如， 当输入的array是[1, 0, 3, 0, 5]  (0, 0)	1  (0, 2)	3  (1, 1)	5   ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/09/11/neo4j%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/" title="neo4j基本使用">neo4j基本使用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-09-11T11:09:51.000Z" title="Created 2023-09-11 19:09:51">2023-09-11</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-04T07:08:32.898Z" title="Updated 2023-11-04 15:08:32">2023-11-04</time></span></div><div class="content">

1. neo4j数据类型1.Node: 节点， 基本语法：Node(label, *properties)
第一步：连接neo4j数据库
1234from py2neo import *url = &quot;http://localhost:7474&quot;graph = Graph(url, username=&quot;neo4j&quot;, password=&quot;szyh&quot;)
第二步：创建节点：
12345678910# 建立节点node_1 = Node(&quot;英雄&quot;, name=&quot;张无忌&quot;)node_2 = Node(&quot;英雄&quot;, name=&quot;杨道&quot;, 武力值=&#x27;100&#x27;)node_3 = Node(&quot;派别&quot;, name=&quot;明教&quot;)# 存入图数据库graph.create(node_1)graph.create(node_2)graph.create(node_3)print(node_1)

2 relation ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#content-inner">4</a><a class="extend next" rel="next" href="/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='https://gitee.com/guudman/blog_images/raw/master/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">AI4Future</div><div class="author-info__description">Not Only Look Once</div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/GuudMan" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2663017379@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">微信公众号: AI4Future</div></div><div class="sticky_layout"><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">32</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div></div></div></div></div></main><footer id="footer" style="background: #FFFFFF"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By AI4Future</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/chenxz21/hexo-theme-bcxm">Bcxm</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://fastly.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script type="text/javascript" src="https://fastly.jsdelivr.net/npm/leancloud-storage@4.10.0/dist/av-min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>