<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>彭能的博客</title>
  
  
  <link href="https://guudman.github.io/atom.xml" rel="self"/>
  
  <link href="https://guudman.github.io/"/>
  <updated>2023-11-02T11:59:41.964Z</updated>
  <id>https://guudman.github.io/</id>
  
  <author>
    <name>Neng Peng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>pytorch全连接层模拟回归</title>
    <link href="https://guudman.github.io/2023/11/02/pytorch%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E6%A8%A1%E6%8B%9F%E5%9B%9E%E5%BD%92/"/>
    <id>https://guudman.github.io/2023/11/02/pytorch%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E6%A8%A1%E6%8B%9F%E5%9B%9E%E5%BD%92/</id>
    <published>2023-11-02T11:58:58.000Z</published>
    <updated>2023-11-02T11:59:41.964Z</updated>
    
    <content type="html"><![CDATA[<h4 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h4><p>搭建两层全连接网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_feature, n_hidden, n_output</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)</span><br><span class="line">        self.predict = torch.nn.Linear(n_hidden, n_output)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.hidden(x))</span><br><span class="line">        x = self.predict(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>预测的值画成曲线</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @File       : 301_regression.py</span></span><br><span class="line"><span class="string"># @Time       ：</span></span><br><span class="line"><span class="string"># @Author     ：</span></span><br><span class="line"><span class="string"># @version    ：python 3.9</span></span><br><span class="line"><span class="string"># @Software   : PyCharm</span></span><br><span class="line"><span class="string"># @Description：</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># ================【功能：】====================</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> animation</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>]=<span class="string">&quot;TRUE&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># x data (tensor), shape=(100, 1)</span></span><br><span class="line">x = torch.unsqueeze(torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100</span>), dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># noisy y data (tensor), shappe(100, 1)</span></span><br><span class="line">y = x.<span class="built_in">pow</span>(<span class="number">2</span>) + <span class="number">0.2</span> * torch.rand(x.size())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># torch can only train on Variable, so convert them to Variable</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_feature, n_hidden, n_output</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)</span><br><span class="line">        self.predict = torch.nn.Linear(n_hidden, n_output)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.hidden(x))</span><br><span class="line">        x = self.predict(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net(n_feature=<span class="number">1</span>, n_hidden=<span class="number">10</span>, n_output=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># 针对回归的均方误差</span></span><br><span class="line">loss_func = torch.nn.MSELoss()</span><br><span class="line">plt.ion()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    prediction = net(x)</span><br><span class="line">    loss = loss_func(prediction, y)</span><br><span class="line">    <span class="comment"># clear gradients for next train</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># backpropagation, comupte gradients</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># apply gradients</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        plt.cla()</span><br><span class="line">        plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">        <span class="comment"># 绘制预测的值</span></span><br><span class="line">        plt.plot(x.data.numpy(), prediction.data.numpy(), <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>)</span><br><span class="line">        plt.text(<span class="number">0.5</span>, <span class="number">0</span>, <span class="string">&#x27;Loss=%.4f&#x27;</span> % loss.data.numpy(), fontdict=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;red&#x27;</span>&#125;)</span><br><span class="line">        <span class="comment"># plt.pause(0.1)</span></span><br><span class="line">        <span class="comment"># plt.ioff()</span></span><br><span class="line">        <span class="comment"># 保存为jpg图像</span></span><br><span class="line">        plt.savefig(<span class="string">f&#x27;./img/regression_<span class="subst">&#123;t&#125;</span>.jpg&#x27;</span>)</span><br><span class="line">        <span class="comment"># plt.show()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>jgp图像转gif动图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @File       : jpg_2_gif.py</span></span><br><span class="line"><span class="string"># @Time       ：</span></span><br><span class="line"><span class="string"># @Author     ：</span></span><br><span class="line"><span class="string"># @version    ：python 3.9</span></span><br><span class="line"><span class="string"># @Software   : PyCharm</span></span><br><span class="line"><span class="string"># @Description：</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># ================【功能：】====================</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    root_path = <span class="string">&#x27;../img&#x27;</span></span><br><span class="line">    image_list = os.listdir(root_path)</span><br><span class="line">    gif_name = <span class="string">&#x27;./regression.gif&#x27;</span></span><br><span class="line">    <span class="comment"># duration between images</span></span><br><span class="line">    duration = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#### read images and write in gif</span></span><br><span class="line">    images = []</span><br><span class="line">    <span class="keyword">for</span> image_name <span class="keyword">in</span> image_list:</span><br><span class="line">        image_name = os.path.join(root_path, image_name)</span><br><span class="line">        images.append(imageio.imread(image_name))</span><br><span class="line">    imageio.mimwrite(gif_name, images, <span class="string">&#x27;GIF&#x27;</span>, duration=duration)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;success&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="结果可视化"><a href="#结果可视化" class="headerlink" title="结果可视化"></a>结果可视化</h4><p><img src="/images/regression.gif" alt="regression"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;实现过程&quot;&gt;&lt;a href=&quot;#实现过程&quot; class=&quot;headerlink&quot; title=&quot;实现过程&quot;&gt;&lt;/a&gt;实现过程&lt;/h4&gt;&lt;p&gt;搭建两层全连接网络&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td </summary>
      
    
    
    
    
    <category term="pytorch" scheme="https://guudman.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>GoogleNet解析</title>
    <link href="https://guudman.github.io/2023/11/02/GoogleNet%E8%A7%A3%E6%9E%90/"/>
    <id>https://guudman.github.io/2023/11/02/GoogleNet%E8%A7%A3%E6%9E%90/</id>
    <published>2023-11-02T11:37:32.000Z</published>
    <updated>2023-11-02T11:40:28.429Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h4><p>GoogleNet在2014年由Google团队提出，斩获当年ImageNet竞赛中Classification Task分类任务第一名。</p><p>论文原文： <a href="%5Barxiv.org/pdf/1409.4842.pdf%5D(https://arxiv.org/pdf/1409.4842.pdf)">GoogleNet原文</a></p><p><img src="/images/googlenet1.jpg" alt="googlenet1"></p><p>首先介绍一下该网络的亮点：</p><ul><li><p>引入Inception结构(融合不同尺度的特征信息)</p></li><li><p>使用1×1的卷积核进行降维以及映射处理</p></li><li><p>添加两个辅助分类器帮助训练</p></li><li><p>丢弃全连接层，使用平均池化层(大大减少模型参数, 除去两个辅助分类器， 网络大小只有vgg的1&#x2F;20)</p></li></ul><p>接着分析一下Inception结构：</p><p><img src="/images/image-20231102141742833.png" alt="image-20231102141742833"></p><p>​左图是论文中提出的inception原始结构， 右图是inception加上降维功能的结构。</p><p>先看<strong>左图</strong>， inception一共有4个分支， 也就是说输入的特征矩阵并行通过这个4个分支得到四个输出， 然后在将这个四个输出在深度维度(channel维度)进行拼接得到最终的输出(<strong>注意：为了让四个分支的输出能够在深度方向进行拼接， 必须保证四个分支输出的特征矩阵高度和宽度都相同</strong>)</p><p>分支1是卷积核大小为1×1的卷积层， stride&#x3D;1</p><p>分支2是卷积核大小为3×3的卷积层， stride&#x3D;1， padding&#x3D;1(保证输出特征矩阵的高和宽和输入特征矩阵相等)</p><p>分支3是卷积核大小为5×5的卷积层， stride&#x3D;1， padding&#x3D;2(保证输出特征矩阵的高和宽和输入特征矩阵相等)</p><p>分支4是池化核大小为3×3的最大池化下采样层， stride&#x3D;1， padding&#x3D;1(保证输出特征矩阵的高和宽和输入特征矩阵相等)</p><p>在看<strong>右图</strong>， 对比左图， 就是在分支2,3,4上加入了卷积核为1×1的卷积层， 目的是为了降维， 减少模型训练参数， 减少计算量。</p><p>下面看一下1×1卷积核如何减少模型参数的， 同样是对一个深度为512的特征矩阵使用64个大小为5×5的卷积核进行卷积， 不使用1×1卷积核进行降维一共需要819200个参数， 如果使用1×1卷积核进行降维， 一共需要50688个参数，明显减少了很多。</p><p><img src="/images/image-20231102143154611.png" alt="image-20231102143154611"></p><p>每个卷积核的参数如何确定呢， 下面是原论文中给出的参数列表， 对于我们搭建的inception模块， 所需要使用的参数有**#1x1, #3x3reduce, #3x3, #5x5reduce, #5x5, poolproj<strong>这6个参数， 分别对应着所需要的</strong>卷积核的个数**。</p><p>下面将inception模块所用到的参数信息标注在每个分支上， #1x1对应着分支上1x1的卷积核个数， #3x3reduce对应着分支2上1x1的卷积核个数， #3x3对应着分支2上3x3的卷积核个数， #5x5reduce对应着分支3上1x1的卷积核个数， #5x5对应着分支3上5x5的卷积核个数，poolproj对应着分支4上1x1的卷积核个数。</p><p><img src="/images/image-20231102144232732.png" alt="image-20231102144232732"></p><p>接下来看辅助分类器结构，网络中的两个辅助分类器结构一模一样的， 如下图所示：</p><p><img src="/images/image-20231102145636207.png" alt="image-20231102145636207"></p><p>这两个辅助分类器的输入分别来自Inception(4a)和inception(4d)。</p><p>辅助分类器的第一层是一个平均池化下采样层， 池化核大小为5x5， stride&#x3D;3， </p><p>第二层是卷积层， 卷积核大小为1x1, stride&#x3D;1, 卷积核个数是128</p><p>第三层是全连接层， 节点个数为1024</p><p>第四层是全连接层， 节点个数为1000(对应分类任务中分类类别数)</p><p>下面给出了GoogleNet网络结构图</p><p><img src="/images/Screen_Shot_googlenet.png" alt="Screen_Shot_googlenet"></p><h4 id="2、代码实现"><a href="#2、代码实现" class="headerlink" title="2、代码实现"></a>2、代码实现</h4><h5 id="1、pytorch实现"><a href="#1、pytorch实现" class="headerlink" title="1、pytorch实现"></a>1、pytorch实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @File       : model_googlenet.py</span></span><br><span class="line"><span class="string"># @Time       ：</span></span><br><span class="line"><span class="string"># @Author     ：</span></span><br><span class="line"><span class="string"># @version    ：python 3.9</span></span><br><span class="line"><span class="string"># @Software   : PyCharm</span></span><br><span class="line"><span class="string"># @Description：</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># ================【功能：】====================</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># pytorch官方参考代码：https://github.com/pytorch/vision/blob/main/torchvision/models/googlenet.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GoogleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span>, aux_logits=<span class="literal">True</span>, init_weights=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(GoogleNet, self).__init__()</span><br><span class="line">        self.aux_logits = aux_logits</span><br><span class="line">        <span class="comment"># (224 - 7 + 2 * 3)/2 + 1 = 112 (3, 224, 224) -&gt; (64, 112, 112)</span></span><br><span class="line">        self.conv1 = BaseConv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">7</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># (64, 112, 112) -&gt; (64, 56, 56) 看一下这里的参数是如何计算的，</span></span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># (56 - 3 + 2 * 0)/1 + 1 = 56 (64, 56, 56) -&gt; (64, 56, 56)</span></span><br><span class="line">        self.conv2 = BaseConv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># (56 - 3 + 2 * 0)/1 + 1 = 56 (64, 56, 56) -&gt; (192, 56, 56)</span></span><br><span class="line">        self.conv3 = BaseConv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">192</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (192, 56, 56) -&gt; (192. 28. 28)</span></span><br><span class="line">        self.maxpool2 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Inception3a 具体参数可查看表</span></span><br><span class="line">        self.inception3a = Inception(<span class="number">192</span>, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">        self.inception3b = Inception(<span class="number">256</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>, <span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">        self.maxpool3 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.inception4a = Inception(<span class="number">480</span>, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4b = Inception(<span class="number">512</span>, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4c = Inception(<span class="number">512</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4d = Inception(<span class="number">512</span>, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">        self.inception4e = Inception(<span class="number">528</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">        self.maxpool4 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.inception5a = Inception(<span class="number">832</span>, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">        self.inception5b = Inception(<span class="number">832</span>, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.aux_logits:</span><br><span class="line">            <span class="comment"># Inception4b  512</span></span><br><span class="line">            self.aux1 = InceptionAux(<span class="number">512</span>, num_classes)</span><br><span class="line">            <span class="comment"># Inception4e 528</span></span><br><span class="line">            self.aux2 = InceptionAux(<span class="number">528</span>, num_classes)</span><br><span class="line">        <span class="comment"># 指定输出固定尺寸</span></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.4</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># [N, 3, 224, 224] -&gt; [N, 64, 112, 112]</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="comment"># [N, 64, 112, 112] -&gt; [N, 64, 56, 56]</span></span><br><span class="line">        x = self.maxpool1(x)</span><br><span class="line">        <span class="comment"># [N, 64, 56, 56] -&gt; [N, 56, 56, 64]</span></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        <span class="comment"># [N, 64, 56, 56] -&gt; [N, 56, 56, 192]</span></span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        <span class="comment"># [N, 56, 56, 192] -&gt; [N, 28, 28, 192]</span></span><br><span class="line">        x = self.maxpool2(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [N, 28, 28, 192] -&gt; [N, 28, 28, 256]</span></span><br><span class="line">        x = self.inception3a(x)</span><br><span class="line">        <span class="comment"># [N, 28, 28, 256] -&gt; [N, 28, 28, 480]</span></span><br><span class="line">        x = self.inception3b(x)</span><br><span class="line">        <span class="comment"># [N, 28, 28, 480] - &gt; [N, 14, 14, 480]</span></span><br><span class="line">        x = self.maxpool3(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#  [N, 14, 14, 480] -&gt; [N, 14, 14, 512]</span></span><br><span class="line">        x = self.inception4a(x)</span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:</span><br><span class="line">            aux1 = self.aux1(x)</span><br><span class="line">        <span class="comment">#   [N, 14, 14, 512] -&gt; [N, 14, 14, 512]</span></span><br><span class="line">        x = self.inception4b(x)</span><br><span class="line">        <span class="comment">#   [N, 14, 14, 512] -&gt; [N, 14, 14, 512]</span></span><br><span class="line">        x = self.inception4c(x)</span><br><span class="line">        <span class="comment">#   [N, 14, 14, 512] -&gt; [N, 14, 14, 528]</span></span><br><span class="line">        x = self.inception4d(x)</span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:</span><br><span class="line">            aux2 = self.aux2(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#   [N, 14, 14, 528] -&gt; [N, 14, 14, 832]</span></span><br><span class="line">        x = self.inception4e(x)</span><br><span class="line">        <span class="comment"># [N, 14, 14, 832] - &gt; [N, 7, 7, 832]</span></span><br><span class="line">        x = self.maxpool4(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#  [N, 7, 7, 832] -&gt; [N, 7, 7, 832]</span></span><br><span class="line">        x = self.inception5a(x)</span><br><span class="line">        <span class="comment">#  [N, 7, 7, 832] -&gt; [N, 7, 7, 1024]</span></span><br><span class="line">        x = self.inception5b(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#  [N, 7, 7, 1024] -&gt; [N, 1, 1, 1024]</span></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        <span class="comment">#  [N, 1, 1, 1024] -&gt; [N, 1024]</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        <span class="comment"># [N, 1024] -&gt; [N, num_classes]</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.aux_logits:</span><br><span class="line">            <span class="keyword">return</span> x, aux2, aux1</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                    nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__()</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        ch1x1: </span></span><br><span class="line"><span class="string">        ch3x3red: ch3x3reduce</span></span><br><span class="line"><span class="string">        ch3x3:</span></span><br><span class="line"><span class="string">        ch5x5red: ch5x5reduce</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.branch1 = BaseConv2d(in_channels, ch1x1, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line">        self.branch2 = nn.Sequential(</span><br><span class="line">            BaseConv2d(in_channels=in_channels, out_channels=ch3x3red, kernel_size=<span class="number">1</span>),</span><br><span class="line">            <span class="comment"># 保证输出大小等于输入大小</span></span><br><span class="line">            BaseConv2d(in_channels=ch3x3red, out_channels=ch3x3, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        self.branch3 = nn.Sequential(</span><br><span class="line">            BaseConv2d(in_channels=in_channels, out_channels=ch5x5red, kernel_size=<span class="number">1</span>),</span><br><span class="line">            <span class="comment"># 保证输出大小等于输入大小</span></span><br><span class="line">            BaseConv2d(in_channels=ch5x5red, out_channels=ch5x5, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.branch4 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            BaseConv2d(in_channels=in_channels, out_channels=pool_proj, kernel_size=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        branch1 = self.branch1(x)</span><br><span class="line">        branch2 = self.branch2(x)</span><br><span class="line">        branch3 = self.branch3(x)</span><br><span class="line">        branch4 = self.branch4(x)</span><br><span class="line"></span><br><span class="line">        outputs = [branch1, branch2, branch3, branch4]</span><br><span class="line">        <span class="comment"># [batch, channel, h, w] torch.cat(outputs, 1)表示在channel维度上拼接</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InceptionAux</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(InceptionAux, self).__init__()</span><br><span class="line">        self.averagepool = nn.AvgPool2d(kernel_size=<span class="number">5</span>, stride=<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># output [batch, 128, 4, 4]</span></span><br><span class="line">        self.conv = BaseConv2d(in_channels, <span class="number">128</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">1024</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># aux1: [N, 512, 14, 14] aux2: [N, 528, 14, 14]</span></span><br><span class="line">        x = self.averagepool(x)</span><br><span class="line">        <span class="comment"># aux1: [N, 512, 4, 4], aux2: [N, 528, 4, 4]</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="comment"># [N, 128, 4, 4]</span></span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.5</span>, training=self.training)</span><br><span class="line">        <span class="comment"># [N, 2048]</span></span><br><span class="line">        x = F.relu(self.fc1(x), inplace=<span class="literal">True</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.5</span>, training=self.training)</span><br><span class="line">        <span class="comment"># [N, 2014]</span></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="comment"># [N, num_classes]</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaseConv2d</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(BaseConv2d, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># input = torch.rand((16, 3, 224, 224))</span></span><br><span class="line"><span class="comment"># googlenet = GoogleNet(num_classes=5, aux_logits=False, init_weights=True)</span></span><br><span class="line"><span class="comment"># print(googlenet)</span></span><br><span class="line"><span class="comment"># output = googlenet(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br></pre></td></tr></table></figure><h5 id="2、TensorFlow实现"><a href="#2、TensorFlow实现" class="headerlink" title="2、TensorFlow实现"></a>2、TensorFlow实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @File       : model_googlenet.py</span></span><br><span class="line"><span class="string"># @Time       ：</span></span><br><span class="line"><span class="string"># @Author     ：0399</span></span><br><span class="line"><span class="string"># @version    ：python 3.9</span></span><br><span class="line"><span class="string"># @Software   : PyCharm</span></span><br><span class="line"><span class="string"># @Description：</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># ================【功能：】====================</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers, models, Model, Sequential</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">GoogleNet</span>(<span class="params">im_height=<span class="number">224</span>, im_width=<span class="number">224</span>, class_num=<span class="number">1000</span>, aux_logits=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># tensorflow通道顺序 NHWC</span></span><br><span class="line">    <span class="comment"># [None, 224, 224, 3]</span></span><br><span class="line">    input_image = layers.Input(shape=(im_height, im_width, <span class="number">3</span>), dtype=<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    <span class="comment"># [None, 224, 224, 3] -&gt; [None, 112, 112, 64]</span></span><br><span class="line">    x = layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">7</span>, strides=<span class="number">2</span>, padding=<span class="string">&quot;SAME&quot;</span>,</span><br><span class="line">                      activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&quot;conv2d_1&quot;</span>)(input_image)</span><br><span class="line">    <span class="comment"># [None, 112, 112, 64] -&gt; [None, 56, 56, 64]</span></span><br><span class="line">    x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">&quot;SAME&quot;</span>, name=<span class="string">&quot;maxpool_1&quot;</span>)(x)</span><br><span class="line">    <span class="comment">#  [None, 56, 56, 64] -&gt;  [None, 56, 56, 64]</span></span><br><span class="line">    x = layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&quot;conv2d_2&quot;</span>)(x)</span><br><span class="line">    <span class="comment">#  [None, 56, 56, 64] -&gt;  [None, 56, 56, 192]  (56 - 3 + 2 * 1)/1 + 1 = 56</span></span><br><span class="line">    x = layers.Conv2D(filters=<span class="number">192</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&quot;conv2d_3&quot;</span>)(x)</span><br><span class="line">    <span class="comment">#  [None, 56, 56, 192] -&gt;  [None, 28, 28, 192]</span></span><br><span class="line"></span><br><span class="line">    x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>)(x)</span><br><span class="line">    <span class="comment">#  [None, 28, 28, 192] -&gt;  [None, 28, 28, 256]</span></span><br><span class="line">    x = Inception(<span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">32</span>, name=<span class="string">&quot;inception3a&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 28, 28, 256] -&gt; [None, 28, 28, 480]</span></span><br><span class="line">    x = Inception(<span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>, <span class="number">96</span>, <span class="number">64</span>, name=<span class="string">&quot;inception3b&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 28, 28, 480] -&gt; [None, 14, 14, 480]</span></span><br><span class="line">    x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">&quot;SAME&quot;</span>, name=<span class="string">&quot;maxpool_2&quot;</span>)(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [None, 14, 14, 480] -&gt; [None, 14, 14, 512]</span></span><br><span class="line">    x = Inception(<span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>, name=<span class="string">&quot;inception4a&quot;</span>)(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> aux_logits:</span><br><span class="line">        aux1 = InceptionAux(class_num, name=<span class="string">&quot;aux1&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 14, 14, 512] -&gt; [None, 14, 14, 512]</span></span><br><span class="line">    x = Inception(<span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>, name=<span class="string">&quot;inception4b&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 14, 14, 512] -&gt; [None, 14, 14, 512]</span></span><br><span class="line">    x = Inception(<span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>, name=<span class="string">&quot;inception4c&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 14, 14, 512] -&gt; [None, 14, 14, 528]</span></span><br><span class="line">    x = Inception(<span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>, name=<span class="string">&quot;inception4d&quot;</span>)(x)</span><br><span class="line">    <span class="keyword">if</span> aux_logits:</span><br><span class="line">        aux2 = InceptionAux(class_num, name=<span class="string">&quot;aux2&quot;</span>)(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [None, 14, 14, 528] -&gt; [None, 14, 14, 832]</span></span><br><span class="line">    x = Inception(<span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>, name=<span class="string">&quot;inception4e&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 14, 14, 832] -&gt; [None, 7, 7, 832]</span></span><br><span class="line">    x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">&quot;SAME&quot;</span>, name=<span class="string">&quot;maxpool_3&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 7, 7, 832] -&gt; [None, 7, 7, 832]</span></span><br><span class="line">    x = Inception(<span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>, name=<span class="string">&quot;inception5a&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 7, 7, 832] -&gt; [None, 7, 7, 1024]</span></span><br><span class="line">    x = Inception(<span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>, <span class="number">128</span>, <span class="number">128</span>, name=<span class="string">&quot;inception5b&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 7, 7, 1024] -&gt; [None, 1, 1, 1024]</span></span><br><span class="line">    x = layers.AvgPool2D(pool_size=<span class="number">7</span>, strides=<span class="number">1</span>, name=<span class="string">&quot;avgpool_1&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 1, 1, 1024] -&gt; [None, 1024*1*1]</span></span><br><span class="line">    x = layers.Flatten(name=<span class="string">&quot;output_flatten&quot;</span>)(x)</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    x = layers.Dropout(rate=<span class="number">0.4</span>, name=<span class="string">&quot;output_dropout&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, class_num]</span></span><br><span class="line">    x = layers.Dense(class_num, name=<span class="string">&quot;output_dense&quot;</span>)(x)</span><br><span class="line"></span><br><span class="line">    aux3 = layers.Softmax(name=<span class="string">&quot;aux_3&quot;</span>)(x)</span><br><span class="line">    <span class="keyword">if</span> aux_logits:</span><br><span class="line">        model = models.Model(inputs=input_image, outputs=[aux1, aux2, aux3])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model = models.Model(inputs=input_image, outputs=aux3)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__()</span><br><span class="line">        self.branch1 = layers.Conv2D(filters=ch1x1, kernel_size=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.branch2 = Sequential([</span><br><span class="line">            layers.Conv2D(filters=ch3x3red, kernel_size=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filters=ch3x3, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;SAME&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)])</span><br><span class="line"></span><br><span class="line">        self.branch3 = Sequential([</span><br><span class="line">            layers.Conv2D(filters=ch5x5red, kernel_size=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filters=ch5x5, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;SAME&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)])</span><br><span class="line"></span><br><span class="line">        self.branch4 = Sequential([</span><br><span class="line">            <span class="comment"># caution: default stride=pool_size</span></span><br><span class="line">            layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">&quot;SAME&quot;</span>),</span><br><span class="line">            layers.Conv2D(filters=pool_proj, kernel_size=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, <span class="built_in">input</span>, **kwargs</span>):</span><br><span class="line">        branch1 = self.branch1(<span class="built_in">input</span>)</span><br><span class="line">        branch2 = self.branch2(<span class="built_in">input</span>)</span><br><span class="line">        branch3 = self.branch3(<span class="built_in">input</span>)</span><br><span class="line">        branch4 = self.branch4(<span class="built_in">input</span>)</span><br><span class="line">        outputs = layers.concatenate([branch1, branch2, branch3, branch4])</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InceptionAux</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(InceptionAux, self).__init__()</span><br><span class="line">        self.avgpool = layers.AvgPool2D(pool_size=<span class="number">5</span>, strides=<span class="number">3</span>)</span><br><span class="line">        self.conv = layers.Conv2D(<span class="number">128</span>, kernel_size=<span class="number">1</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1 = layers.Dense(units=<span class="number">1024</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.fc2 = layers.Dense(units=num_classes)</span><br><span class="line">        self.softmax = layers.Softmax()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, **kwargs</span>):</span><br><span class="line">        <span class="comment"># aux1 [None, 14, 14, 512] aux2 [None, 14, 14, 528]</span></span><br><span class="line">        <span class="comment"># aux1: [None, 14, 14, 512] -&gt; [None, 4, 4, 512]  (14 - 5)/3 + 1 = 4</span></span><br><span class="line">        <span class="comment"># axu2: [None, 14, 14, 528] -&gt; [None, 4, 4, 528]  (14 - 5)/3 + 1 = 4</span></span><br><span class="line">        x = self.avgpool(inputs)</span><br><span class="line">        <span class="comment"># aux1 [None, 4, 4, 512]-&gt; [4, 4, 512]  aux2 [None, 4, 4, 528]-&gt; [4, 4, 528]</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        x = layers.Flatten()(x)</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = layers.Dropout(rate=<span class="number">0.5</span>)(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = layers.Dropout(rate=<span class="number">0.5</span>)(x)</span><br><span class="line">        x = self.softmax(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># input = tf.random.uniform((16, 224, 224, 3))</span></span><br><span class="line"><span class="comment"># googlenet = GoogleNet(class_num=5, aux_logits=False)</span></span><br><span class="line"><span class="comment"># output = googlenet(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;1、简介&quot;&gt;&lt;a href=&quot;#1、简介&quot; class=&quot;headerlink&quot; title=&quot;1、简介&quot;&gt;&lt;/a&gt;1、简介&lt;/h4&gt;&lt;p&gt;GoogleNet在2014年由Google团队提出，斩获当年ImageNet竞赛中Classification Task分</summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://guudman.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>VggNet解析</title>
    <link href="https://guudman.github.io/2023/11/02/VggNet%E8%A7%A3%E6%9E%90/"/>
    <id>https://guudman.github.io/2023/11/02/VggNet%E8%A7%A3%E6%9E%90/</id>
    <published>2023-11-02T11:17:44.000Z</published>
    <updated>2023-11-02T11:21:17.531Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h4><p>论文原文： [VggNet原文](<a href="https://arxiv.org/pdf/1409.1556.pdf">1409.1556.pdf (arxiv.org)</a>)</p><p>VGG由牛津大学视觉几何小组(Visual Geometry Group, VGG)提出的一种深层卷积网， 该网络在2014年获得定位任务的第一名， 分类任务的第二名。VGG可以看成是加深版的AlexNet， 都是conv + FC layer组成。</p><p>下图是VGG16模型的结构简图</p><p><img src="/images/image-20231102101734336.png"></p><p><strong>网络的亮点</strong></p><ul><li>通过堆叠多个3×3的卷积代替大尺度卷积核 (在保证相同感受野的前提下能够减少所需的参数量)</li></ul><p>论文中提到，通过堆叠两个3×3的卷积核代替5×5的卷积核， 堆叠三个3×3的卷积核代替7×7的卷积核。It is easy to see that a stack of <strong>two</strong> <strong>3</strong> <strong>× 3</strong> conv layers (without spatial pooling in between) has an effective receptive field of <strong>5 × 5</strong>; <strong>three</strong> such layers have a <strong>7 × 7</strong> effective receptive field.</p><p>下面给出一个实例</p><p>使用7×7卷积核所需参数， 假设输入输出通道数均为C。</p><p>7×7×C×C &#x3D; 49C²</p><p>堆叠3个3×3卷积核所需参数， 假设输入输出通道数均为C。</p><p>3×3×C×C + 3×3×C×C + 3×3×C×C &#x3D; 27C²</p><p>经过对比发现使用3层3×3的卷积层比使用7×7的卷积核参数更少。</p><p>下图是从原论文中截取的几种VGG模型的配置表， 表中作者呈现了几种不同深度的配置(11层, 13层， 16层， 19层)是否使用<strong>LRN</strong>以及1×1卷积层与3×3卷积层的差异。</p><p><img src="/images/image-20231102102435922.png"></p><h4 id="2、代码实现"><a href="#2、代码实现" class="headerlink" title="2、代码实现"></a>2、代码实现</h4><h5 id="1、pytorch实现"><a href="#1、pytorch实现" class="headerlink" title="1、pytorch实现"></a>1、pytorch实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @File       : model_vgg.py</span></span><br><span class="line"><span class="string"># @Time       ：</span></span><br><span class="line"><span class="string"># @Author     ：</span></span><br><span class="line"><span class="string"># @version    ：python 3.9</span></span><br><span class="line"><span class="string"># @Software   : PyCharm</span></span><br><span class="line"><span class="string"># @Description：</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># ================【功能：】====================</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先搭建vgg19</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VggNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(VggNet, self).__init__()</span><br><span class="line">        <span class="comment"># (224 - 3 + 2*1)/1 + 1 = 224 -&gt; (224, 224, 64)</span></span><br><span class="line">        self.conv1_64_1 = nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># (223 - 3 + 2*1)1 + 1 = 224 -&gt; (224, 224, 64)</span></span><br><span class="line">        self.conv1_64_2 = nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># (224, 224, 64) -&gt; (112, 112, 64)</span></span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># (112 - 3 + 2*1)/1 + 1 = 112  (112, 112, 64) -&gt; (112, 112, 128)</span></span><br><span class="line">        self.conv2_128_1 = nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2_128_2 = nn.Conv2d(in_channels=<span class="number">128</span>, out_channels=<span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># (112, 128, 128) -&gt; (56, 56, 128)</span></span><br><span class="line">        self.maxpool2 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># (56 - 3 + 2 * 1)/ 1 + 1 = 56 (56, 56, 128) -&gt; (56, 56, 256)</span></span><br><span class="line">        self.conv3_256_1 = nn.Conv2d(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv3_256_2 = nn.Conv2d(in_channels=<span class="number">256</span>, out_channels=<span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv3_256_3 = nn.Conv2d(in_channels=<span class="number">256</span>, out_channels=<span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># maxpool  (56, 56, 256) -&gt; (28, 28, 256)</span></span><br><span class="line">        self.maxpool3 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.conv4_512_1 = nn.Conv2d(in_channels=<span class="number">256</span>, out_channels=<span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv4_512_2 = nn.Conv2d(in_channels=<span class="number">512</span>, out_channels=<span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv4_512_3 = nn.Conv2d(in_channels=<span class="number">512</span>, out_channels=<span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># maxpool (28, 28, 512) -&gt; (14, 14, 512)</span></span><br><span class="line">        self.maxpool4 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># (14, 14, 512)</span></span><br><span class="line">        self.conv5_512_1 = nn.Conv2d(in_channels=<span class="number">512</span>, out_channels=<span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv5_512_2 = nn.Conv2d(in_channels=<span class="number">512</span>, out_channels=<span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv5_512_3 = nn.Conv2d(in_channels=<span class="number">512</span>, out_channels=<span class="number">512</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># maxpool (14, 14, 512) -&gt; (7, 7, 512)</span></span><br><span class="line">        self.maxpool5 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">7</span> * <span class="number">7</span> * <span class="number">512</span>, <span class="number">4096</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>)</span><br><span class="line">        self.fc3 = nn.Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1_64_1(x)</span><br><span class="line">        x = self.conv1_64_2(x)</span><br><span class="line">        x = self.maxpool1(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv2_128_1(x)</span><br><span class="line">        x = self.conv2_128_2(x)</span><br><span class="line">        x = self.maxpool2(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv3_256_1(x)</span><br><span class="line">        x = self.conv3_256_2(x)</span><br><span class="line">        x = self.conv3_256_3(x)</span><br><span class="line">        x = self.maxpool3(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv4_512_1(x)</span><br><span class="line">        x = self.conv4_512_2(x)</span><br><span class="line">        x = self.conv4_512_3(x)</span><br><span class="line">        x = self.maxpool4(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv5_512_1(x)</span><br><span class="line">        x = self.conv5_512_2(x)</span><br><span class="line">        x = self.conv5_512_3(x)</span><br><span class="line">        x = self.maxpool5(x)  <span class="comment"># [batch, c, h, w] -&gt; [-1, c*h*w]</span></span><br><span class="line"></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">512</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># input = torch.rand([8, 3, 224, 224])</span></span><br><span class="line"><span class="comment"># vggnet = VggNet()</span></span><br><span class="line"><span class="comment"># print(vggnet)</span></span><br><span class="line"><span class="comment"># output = vggnet(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br></pre></td></tr></table></figure><h5 id="2、TensorFlow实现"><a href="#2、TensorFlow实现" class="headerlink" title="2、TensorFlow实现"></a>2、TensorFlow实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @File       : model_vggnet.py</span></span><br><span class="line"><span class="string"># @Time       ：</span></span><br><span class="line"><span class="string"># @Author     ：0399</span></span><br><span class="line"><span class="string"># @version    ：python 3.9</span></span><br><span class="line"><span class="string"># @Software   : PyCharm</span></span><br><span class="line"><span class="string"># @Description：</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># ================【功能：】====================</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers, Model, Sequential</span><br><span class="line"></span><br><span class="line">CONV_KERNEL_INITIALIZER = &#123;</span><br><span class="line">    <span class="string">&#x27;class_name&#x27;</span>: <span class="string">&#x27;VarianceScaling&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;config&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;scale&#x27;</span>: <span class="number">2.0</span>,</span><br><span class="line">        <span class="string">&#x27;mode&#x27;</span>: <span class="string">&#x27;fan_out&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;distribution&#x27;</span>: <span class="string">&#x27;truncated_normal&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DENSE_KERNEL_INITIALIZER = &#123;</span><br><span class="line">    <span class="string">&#x27;class_name&#x27;</span>: <span class="string">&#x27;VarianceScaling&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;config&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;scale&#x27;</span>: <span class="number">1.</span> / <span class="number">3.</span>,</span><br><span class="line">        <span class="string">&#x27;mode&#x27;</span>: <span class="string">&#x27;fan_out&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;distribution&#x27;</span>: <span class="string">&#x27;uniform&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">VGG</span>(<span class="params">feature, im_height=<span class="number">224</span>, im_width=<span class="number">224</span>, num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># tensorflow中的tensor通道顺序是NHWC</span></span><br><span class="line">    input_image = layers.Input(shape=(im_height, im_width, <span class="number">3</span>), dtype=<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    x = feature(input_image)</span><br><span class="line">    x = layers.Flatten()(x)</span><br><span class="line">    x = layers.Dropout(rate=<span class="number">0.5</span>)(x)</span><br><span class="line">    x = layers.Dense(<span class="number">2048</span>, activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                     kernel_initializer=DENSE_KERNEL_INITIALIZER)(x)</span><br><span class="line">    x = layers.Dropout(rate=<span class="number">0.5</span>)(x)</span><br><span class="line">    x = layers.Dense(<span class="number">2048</span>, activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                     kernel_initializer=DENSE_KERNEL_INITIALIZER)(x)</span><br><span class="line">    x = layers.Dropout(rate=<span class="number">0.5</span>)(x)</span><br><span class="line">    x = layers.Dense(num_classes, activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                     kernel_initializer=DENSE_KERNEL_INITIALIZER)(x)</span><br><span class="line">    output = layers.Softmax()(x)</span><br><span class="line"></span><br><span class="line">    model = Model(inputs=input_image, outputs=output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_feature</span>(<span class="params">cfg</span>):</span><br><span class="line">    feature_layers = []</span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&#x27;M&#x27;</span>:</span><br><span class="line">            feature_layers.append(layers.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            feature_layers.append(layers.Conv2D(v, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>,</span><br><span class="line">                                                kernel_initializer=CONV_KERNEL_INITIALIZER))</span><br><span class="line">    <span class="keyword">return</span> Sequential(feature_layers, name=<span class="string">&quot;feature&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cfgs = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">model_name=<span class="string">&quot;vgg16&quot;</span>, im_height=<span class="number">224</span>, im_width=<span class="number">224</span>, num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    cfg = cfgs[model_name]</span><br><span class="line">    model = VGG(make_feature(cfg), im_height=im_height, im_width=im_width, num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># input = tf.random.uniform((4, 224, 224, 3))</span></span><br><span class="line"><span class="comment"># vggnet = vgg(&quot;vgg16&quot;, num_classes=5)</span></span><br><span class="line"><span class="comment"># print(vggnet.summary())</span></span><br><span class="line"><span class="comment"># print(vggnet(input))</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;1、简介&quot;&gt;&lt;a href=&quot;#1、简介&quot; class=&quot;headerlink&quot; title=&quot;1、简介&quot;&gt;&lt;/a&gt;1、简介&lt;/h4&gt;&lt;p&gt;论文原文： [VggNet原文](&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;</summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://guudman.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>AlexNet解析</title>
    <link href="https://guudman.github.io/2023/11/02/AlexNet%E8%A7%A3%E6%9E%90/"/>
    <id>https://guudman.github.io/2023/11/02/AlexNet%E8%A7%A3%E6%9E%90/</id>
    <published>2023-11-02T11:11:45.000Z</published>
    <updated>2023-11-02T11:14:15.476Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、AlexNet简介"><a href="#1、AlexNet简介" class="headerlink" title="1、AlexNet简介"></a>1、AlexNet简介</h4><p>Alexnet是2012年ILSVRC 2012(ImageNet Large Scale Visual Recognition Challenge)竞赛的冠军网络， 分类准确率由传统的70%提升到80%(当时传统方法已进入瓶颈期，所以这么大的提升是非常厉害的)。它是由Hinton和他的学生Alex设计的。也是在那年之后，深度学习模型开始迅速发展。下面的图就是Alexnet原论文中截取的网络结构图。</p><p>Alexnet论文原文， <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">AlexNet</a></p><p><img src="/images/image-20231102091945023.png" alt="image-20231102091945023"></p><p>图中有上下两部分是因为作者使用两块GPU进行并行训练， 所以上下两部分的结果是一模一样的。我们直接看下面部分就行了。</p><p>接着说说该网络的亮点：</p><p>(1)首次使用了GPU进行网络加速训练</p><p>(2)使用了ReLU激活函数， 而不是传统的Sigmoid激活函数以及Tanh激活函数</p><p>(3)使用了LRN局部相应归一化</p><p>(4)在全连接层的前两层使用了Dropout方法按照一定比例随机失活神经元，以减少过拟合</p><p>接着给出卷积或池化后的矩阵尺寸大小计算公式</p><p>N &#x3D; (W - F  + 2p)&#x2F;s + 1</p><p>其中w是输入图片大小， F是 卷积核或池化核大小， p是padding的像素个数， s是步距。</p><p>接下来对每一层进行详细分析</p><h4 id="2、模型结构参数剖析"><a href="#2、模型结构参数剖析" class="headerlink" title="2、模型结构参数剖析"></a>2、模型结构参数剖析</h4><p><strong>卷积层1</strong></p><p>由于使用了两块GPU， 所以卷积核的个数需要乘以2：</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Conv1:</span><br><span class="line">    input<span class="built_in">_</span>size: [224, 224, 3] -&gt; output：(224 – 11 + (1 + 2))/4 + 1=55 -&gt;(55, 55, 96)</span><br><span class="line">    kernels: 48 * 2</span><br><span class="line">    kernel<span class="built_in">_</span>size: 11</span><br><span class="line">    stride: 4</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>**Conv1: kernels&#x3D;48 × 2 &#x3D; 96， kernel_size&#x3D;11, padding&#x3D;[1, 2], stride&#x3D;4 **</p><p>因此卷积核的个数为96， kernel_size代表卷积核的尺寸， padding代表特征矩阵上下左右补零的参数，stride代表步距。</p><p>输入图片的shape&#x3D;[224, 224, 3]， 输出矩阵的计算公式为： (224  - 11 + (1 + 2)) &#x2F; 4 + 1 &#x3D; 55</p><p>所以输出矩阵的shape为[55, 55, 96]</p><p><strong>Conv1</strong>的实现过程【两个GPU计算过程一模一样，所以kernels就按照一块GPU来搭建】</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytroch</span></span><br><span class="line">self.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>, kernel_size=<span class="number">11</span>, out_channels=<span class="number">48</span>, padding=<span class="number">2</span>, stride=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">x = layers.Conv2D(filters=<span class="number">48</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br></pre></td></tr></table></figure><p><strong>最大池化下采样层1</strong></p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">maxpooling1: </span><br><span class="line">input<span class="built_in">_</span>size:(55, 55, 96) kernel<span class="built_in">_</span>size:3</span><br><span class="line">padding:0</span><br><span class="line">stride:2</span><br><span class="line">outpu<span class="built_in">_</span>size(27, 27, 96)</span><br></pre></td></tr></table></figure><p><strong>Maxpool1: kernel_size&#x3D;3, padding&#x3D;0, stride&#x3D;2</strong></p><p>kernel_size表示池化核大小， padding表示矩阵上下左右补零的参数， stride代表步距。</p><p>输入特征矩阵的shape&#x3D;[55, 55, 96], 输出特征矩阵的shape&#x3D;[27, 27 , 96]</p><p>shape计算： (W -F + 2P)&#x2F;S+1 &#x3D; (55 - 3 + 2*0)&#x2F;2 + 1&#x3D;27</p><p><strong>Maxpool1</strong>的实现过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch:</span></span><br><span class="line">self.maxpooling1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line">x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>)(x)  <span class="comment"># [None, 27, 27, 48]</span></span><br></pre></td></tr></table></figure><p><strong>卷积层2</strong></p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Conv2:</span><br><span class="line">input<span class="built_in">_</span>size:[27, 27, 96]</span><br><span class="line">kernel<span class="built_in">_</span>size:5</span><br><span class="line">kernels: 128 * 2</span><br><span class="line">padding:2</span><br><span class="line">stride:1</span><br><span class="line"></span><br><span class="line">output<span class="built_in">_</span>size:[27, 27, 256]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>**Conv2: kernel&#x3D;128×2, kernel_size&#x3D;5, padding&#x3D;2, stride&#x3D;1 **</p><p>输入特征矩阵的深度为[27, 27, 96], 输出特征矩阵尺寸计算公式为：(27 – 5 + 2 * 2)&#x2F;1+ 1&#x3D;27</p><p>所以输出特征矩阵的尺寸为[27, 27, 256]</p><p><strong>Conv2</strong>的实现过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">self.conv2 = nn.Conv2d(in_channels=<span class="number">48</span>, kernel_size=<span class="number">5</span>, out_channels=<span class="number">128</span>, padding=<span class="number">2</span>, stride=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow</span></span><br><span class="line"><span class="comment"># 当stride=1且padding=same时， 表示输出尺寸与输入尺寸相同 -&gt;[None, 27, 27, 128]</span></span><br><span class="line">x = layers.Conv2D(filters=<span class="number">128</span>, kernel_size=<span class="number">5</span>, padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br></pre></td></tr></table></figure><p><strong>最大池化下采样层2</strong></p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">maxpooling2:</span><br><span class="line">input<span class="built_in">_</span>size:[27, 27, 256] </span><br><span class="line">kernel<span class="built_in">_</span>size:3</span><br><span class="line">padding:0</span><br><span class="line">stride:2  </span><br><span class="line">output<span class="built_in">_</span>size:[13, 13, 256]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>Maxpool2: kernel_size&#x3D;3, padding&#x3D;0, stride&#x3D;2</strong></p><p>kernel_size表示池化核大小， padding表示矩阵上下左右补零的参数， stride代表步距。</p><p>输入特征矩阵的shape&#x3D;[27, 27, 256], 输出特征矩阵的shape&#x3D;[13, 13 , 256]</p><p>shape计算： (W -F + 2P)&#x2F;S+1 &#x3D; (27- 3 + 2*0)&#x2F;2 + 1&#x3D;13</p><p><strong>Maxpool2</strong>的实现过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch:</span></span><br><span class="line">self.maxpooling2 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line"><span class="comment"># [None, 27, 27, 128] -&gt; [None, 13, 13, 128]</span></span><br><span class="line">x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>)(x)</span><br></pre></td></tr></table></figure><p><strong>卷积层3</strong></p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conv3:</span><br><span class="line">input<span class="built_in">_</span>size:[13, 13, 256]</span><br><span class="line">kernels: 192*2 = 384</span><br><span class="line">kernel<span class="built_in">_</span>size:3</span><br><span class="line">padding:1</span><br><span class="line">stride:1</span><br><span class="line">output<span class="built_in">_</span>size:[13, 13, 384]</span><br></pre></td></tr></table></figure><p>**Conv3: kernel&#x3D;192×2, kernel_size&#x3D;3, padding&#x3D;1, stride&#x3D;1 **</p><p>输入特征矩阵的深度为[27, 27, 96], 输出特征矩阵尺寸计算公式为：(13– 3 + 2 * 1)&#x2F;1+ 1&#x3D;13</p><p>所以输出特征矩阵的尺寸为[13, 13, 384]</p><p><strong>Conv3</strong>的实现过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">self.conv3 = nn.Conv2d(in_channels=<span class="number">128</span>, kernel_size=<span class="number">3</span>, out_channels=<span class="number">192</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow</span></span><br><span class="line"><span class="comment"># stride=1, padding=same, 输出不变 -&gt;[None, 13, 13, 192]</span></span><br><span class="line">x = layers.Conv2D(filters=<span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>卷积层4</strong></p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">conv4:</span><br><span class="line">input<span class="built_in">_</span>size:[13, 13, 384]</span><br><span class="line">kernels: 192*2 = 384</span><br><span class="line">kernel<span class="built_in">_</span>size:3</span><br><span class="line">padding:1</span><br><span class="line">stride:1</span><br><span class="line"></span><br><span class="line">output<span class="built_in">_</span>size:[13, 13, 384]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>**Conv4: kernel&#x3D;192×2, kernel_size&#x3D;3, padding&#x3D;1, stride&#x3D;1 **</p><p>输入特征矩阵的深度为[13, 13, 384], 输出特征矩阵尺寸计算公式为：(13– 3 + 2 * 1)&#x2F;1+ 1&#x3D;13</p><p>所以输出特征矩阵的尺寸为[13, 13, 384]</p><p><strong>Conv4</strong>的实现过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">self.conv4 = nn.Conv2d(in_channels=<span class="number">192</span>, kernel_size=<span class="number">3</span>, out_channels=<span class="number">192</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow</span></span><br><span class="line"><span class="comment"># -&gt;[None, 13, 13, 192]</span></span><br><span class="line">x = layers.Conv2D(filters=<span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>卷积层5</strong></p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">conv5:</span><br><span class="line"> input<span class="built_in">_</span>size:[13, 13, 384]</span><br><span class="line">kernels: 128*2 = 256</span><br><span class="line">kernel<span class="built_in">_</span>size:3</span><br><span class="line">padding:1</span><br><span class="line">stride:1</span><br><span class="line"></span><br><span class="line">output<span class="built_in">_</span>size:[13, 13, 256]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输入特征矩阵的深度为[13, 13, 384], 输出特征矩阵尺寸计算公式为：(13– 3 + 2 * 1)&#x2F;1+ 1&#x3D;13</p><p>所以输出特征矩阵的尺寸为[13, 13, 256]</p><p><strong>Conv5</strong>的实现过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">self.conv5 = nn.Conv2d(in_channels=<span class="number">192</span>, kernel_size=<span class="number">3</span>, out_channels=<span class="number">128</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line"><span class="comment"># -&gt;[None, 13, 13, 128]</span></span><br><span class="line">x = layers.Conv2D(filters=<span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br></pre></td></tr></table></figure><p><strong>最大池化下采样3</strong></p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">maxpool3:</span><br><span class="line">input<span class="built_in">_</span>size:[13, 13, 256] </span><br><span class="line">kernel<span class="built_in">_</span>size:3</span><br><span class="line">padding:0</span><br><span class="line">stride:2</span><br><span class="line"></span><br><span class="line">output<span class="built_in">_</span>size:[6, 6, 256]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输入特征矩阵的shape&#x3D;[13, 13, 256], 输出特征矩阵的shape&#x3D;[6, 6, 256]</p><p>shape计算： (W -F + 2P)&#x2F;S+1 &#x3D; (13- 3 + 2*0)&#x2F;2 + 1&#x3D;6</p><p><strong>Maxpool3</strong>的实现过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch</span></span><br><span class="line">self.maxpooling3 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># tensorflow</span></span><br><span class="line"><span class="comment"># -&gt;[None, 6, 6, 128]</span></span><br><span class="line">x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>)(x)</span><br></pre></td></tr></table></figure><p><strong>全连接层1</strong></p><p><strong>uni_size: 4096, unit_size为全连接层的节点个数， 两块GPU所以翻倍</strong></p><p><strong>全连接层2</strong></p><p><strong>uni_size: 4096, unit_size为全连接层的节点个数， 两块GPU所以翻倍</strong></p><p><strong>全连接层3</strong></p><p><strong>uni_size: 1000</strong>， 该层为输出层， 输出节点数对应分类任务中分类类别数。</p><h4 id="3、参数列表"><a href="#3、参数列表" class="headerlink" title="3、参数列表"></a>3、参数列表</h4><table><thead><tr><th><strong>名称</strong></th><th align="center"><strong>Input_size</strong></th><th><strong>Kernel_size</strong></th><th><strong>Kernel_num</strong></th><th><strong>padding</strong></th><th><strong>Stride</strong></th><th><strong>Output_size</strong></th><th><strong>尺寸计算</strong></th></tr></thead><tbody><tr><td>Conv1</td><td align="center">(224,  224,3)</td><td>11</td><td>48*2</td><td>[1,2]</td><td>4</td><td>(55, 55, 96)</td><td>(224-11+2*2)4+1&#x3D;55</td></tr><tr><td>Maxpooling1</td><td align="center">(55, 55, 96)</td><td>3</td><td></td><td>0</td><td>2</td><td>(27,  27, 96)</td><td>(55-3+2*0)&#x2F;2+1&#x3D;27</td></tr><tr><td>Conv2</td><td align="center">(27,  27, 96)</td><td>5</td><td>128*2</td><td>2</td><td>1</td><td>(27,27, 256)</td><td>(27-5+2*2)&#x2F;1+1&#x3D;27</td></tr><tr><td>Maxpooling2</td><td align="center">(27,27, 256)</td><td>3</td><td></td><td>0</td><td>2</td><td>(13, 13, 256)</td><td>(27-3+2*0)&#x2F;2+1&#x3D;13</td></tr><tr><td>Conv3</td><td align="center">(13, 13, 256)</td><td>3</td><td>192*2</td><td>1</td><td>1</td><td>(13, 13, 384)</td><td>(13-3+2*1)&#x2F;1+1&#x3D;13</td></tr><tr><td>Conv4</td><td align="center">(13, 13, 384)</td><td>3</td><td>192*2</td><td>1</td><td>1</td><td>(13, 13, 384)</td><td>(13-3+2*1)&#x2F;1+1&#x3D;13</td></tr><tr><td>Conv5</td><td align="center">(13,13, 384)</td><td>3</td><td>128*2</td><td>1</td><td>1</td><td>(13, 13, 256)</td><td>(13-3+2*1)&#x2F;1+1&#x3D;13</td></tr><tr><td>Maxpooling3</td><td align="center">(13,  13, 256)</td><td>3</td><td></td><td>0</td><td>2</td><td>(6,6,256)</td><td>(13-3+2*0)&#x2F;2+1&#x3D;6</td></tr><tr><td>FC1</td><td align="center"></td><td>2048</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>FC2</td><td align="center"></td><td>2048</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>FC3</td><td align="center"></td><td>1000</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><h4 id="4、代码实现"><a href="#4、代码实现" class="headerlink" title="4、代码实现"></a>4、代码实现</h4><h5 id="1、pytorch实现"><a href="#1、pytorch实现" class="headerlink" title="1、pytorch实现"></a>1、pytorch实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @File       : model_alexnet.py</span></span><br><span class="line"><span class="string"># @Time       ：</span></span><br><span class="line"><span class="string"># @Author     ：</span></span><br><span class="line"><span class="string"># @version    ：python 3.9</span></span><br><span class="line"><span class="string"># @Software   : PyCharm</span></span><br><span class="line"><span class="string"># @Description：</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># ================【功能：】====================</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>, kernel_size=<span class="number">11</span>, out_channels=<span class="number">48</span>, padding=<span class="number">2</span>, stride=<span class="number">4</span>)</span><br><span class="line">        self.maxpooling1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">48</span>, kernel_size=<span class="number">5</span>, out_channels=<span class="number">128</span>, padding=<span class="number">2</span>, stride=<span class="number">1</span>)</span><br><span class="line">        self.maxpooling2 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.conv3 = nn.Conv2d(in_channels=<span class="number">128</span>, kernel_size=<span class="number">3</span>, out_channels=<span class="number">192</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line">        self.conv4 = nn.Conv2d(in_channels=<span class="number">192</span>, kernel_size=<span class="number">3</span>, out_channels=<span class="number">192</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line">        self.conv5 = nn.Conv2d(in_channels=<span class="number">192</span>, kernel_size=<span class="number">3</span>, out_channels=<span class="number">128</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line">        self.maxpooling3 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.fc1 = nn.Linear(in_features=<span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>, out_features=<span class="number">2048</span>)</span><br><span class="line">        self.fc2 = nn.Linear(in_features=<span class="number">2048</span>, out_features=<span class="number">2048</span>)</span><br><span class="line">        self.fc3 = nn.Linear(in_features=<span class="number">2048</span>, out_features=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.maxpooling1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.maxpooling2(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = self.conv4(x)</span><br><span class="line">        x = self.conv5(x)</span><br><span class="line">        x = self.maxpooling3(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">128</span> * <span class="number">6</span> * <span class="number">6</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu((self.fc2(x)))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># input = torch.rand([32, 3, 224, 224])</span></span><br><span class="line"><span class="comment"># alexnet = AlexNet()</span></span><br><span class="line"><span class="comment"># print(alexnet)</span></span><br><span class="line"><span class="comment"># output = alexnet(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="2、TensorFlow实现"><a href="#2、TensorFlow实现" class="headerlink" title="2、TensorFlow实现"></a>2、TensorFlow实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @File       : model_alexnet.py</span></span><br><span class="line"><span class="string"># @Time       ：</span></span><br><span class="line"><span class="string"># @Author     ：0399</span></span><br><span class="line"><span class="string"># @version    ：python 3.9</span></span><br><span class="line"><span class="string"># @Software   : PyCharm</span></span><br><span class="line"><span class="string"># @Description：</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># ================【功能：】====================</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers, models, Model, Sequential</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">AlexNet_v1</span>(<span class="params">im_height=<span class="number">224</span>, im_width=<span class="number">224</span>, num_classes=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="comment"># tensorflow中的通道顺序是NHWC</span></span><br><span class="line">    input_image = layers.Input(shape=(im_height, im_width, <span class="number">3</span>), dtype=<span class="string">&quot;float32&quot;</span>)  <span class="comment"># [None, 224, 224, 3]</span></span><br><span class="line">    <span class="comment"># x = layers.Conv2D()</span></span><br><span class="line">    x = layers.ZeroPadding2D(((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">2</span>)))(input_image)  <span class="comment"># [None, 227, 227, 3]</span></span><br><span class="line">    <span class="comment"># (227 - 11 + 2*0) / 4 + 1 = 55  -&gt; [None, 55, 55, 48]</span></span><br><span class="line">    x = layers.Conv2D(filters=<span class="number">48</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>)(x)  <span class="comment"># [None, 27, 27, 48]</span></span><br><span class="line">    <span class="comment"># 当stride=1且padding=same时， 表示输出尺寸与输入尺寸相同 -&gt;[None, 27, 27, 128]</span></span><br><span class="line">    x = layers.Conv2D(filters=<span class="number">128</span>, kernel_size=<span class="number">5</span>, padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 27, 27, 128] -&gt; [None, 13, 13, 128]</span></span><br><span class="line">    x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>)(x)</span><br><span class="line">    <span class="comment"># stride=1, padding=same, 输出不变 -&gt;[None, 13, 13, 192]</span></span><br><span class="line">    x = layers.Conv2D(filters=<span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># -&gt;[None, 13, 13, 192]</span></span><br><span class="line">    x = layers.Conv2D(filters=<span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># -&gt;[None, 13, 13, 128]</span></span><br><span class="line">    x = layers.Conv2D(filters=<span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">1</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># -&gt;[None, 6, 6, 128]</span></span><br><span class="line">    x = layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>)(x)</span><br><span class="line"></span><br><span class="line">    x = layers.Flatten()(x)  <span class="comment"># [None, 128*6*6]</span></span><br><span class="line">    x = layers.Dropout(<span class="number">0.2</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 2048]</span></span><br><span class="line">    x = layers.Dense(<span class="number">2048</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    x = layers.Dropout(<span class="number">0.2</span>)(x)</span><br><span class="line">    <span class="comment"># [None, 2048]</span></span><br><span class="line">    x = layers.Dense(<span class="number">2048</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    x = layers.Dense(num_classes)(x)</span><br><span class="line"></span><br><span class="line">    predict = layers.Softmax()(x)</span><br><span class="line">    <span class="built_in">print</span>(predict)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model = models.Model(inputs=input_image, outputs=predict)</span></span><br><span class="line">    model = models.Model(inputs=input_image, outputs=predict)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet_v2</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">1000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(AlexNet_v2, self).__init__()</span><br><span class="line">        self.features = Sequential([</span><br><span class="line">            <span class="comment"># [None, 224, 224, 3] -&gt; [None, 227, 227, 3]</span></span><br><span class="line">            layers.ZeroPadding2D(((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">2</span>))),</span><br><span class="line">            <span class="comment"># padding=&quot;valid&quot;表示向上取整 (227 - 11)/4 + 1=55 [None, 227, 227, 3]-&gt;[None, 55, 55, 48]</span></span><br><span class="line">            layers.Conv2D(filters=<span class="number">48</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            <span class="comment"># [55, 55, 48] -&gt; [None, 27, 27, 48]</span></span><br><span class="line">            layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>),</span><br><span class="line">            <span class="comment"># stride=1, padding=same, 尺寸不变 [None, 27, 27, 48] -&gt;[None, 27, 27, 128]</span></span><br><span class="line">            layers.Conv2D(filters=<span class="number">128</span>, kernel_size=<span class="number">5</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            <span class="comment"># [None, 27, 27, 128] -&gt;[None, 13, 13, 128]</span></span><br><span class="line">            layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>),</span><br><span class="line">            <span class="comment"># [None, 13, 13, 128] -&gt; [None, 13, 13, 192]</span></span><br><span class="line">            layers.Conv2D(filters=<span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            <span class="comment"># [None, 13, 13, 192] -&gt; [None, 13, 13, 192]</span></span><br><span class="line">            layers.Conv2D(filters=<span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            <span class="comment"># [None, 13, 13, 192] -&gt; [None, 13, 13, 128]</span></span><br><span class="line">            layers.Conv2D(filters=<span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="string">&quot;same&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            <span class="comment"># [None, 13, 13, 128] -&gt; [None, 6, 6, 128]</span></span><br><span class="line">            layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [None, 128*6*6]</span></span><br><span class="line">        self.flatten = layers.Flatten()</span><br><span class="line">        self.classifier = Sequential([</span><br><span class="line">            layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            layers.Dense(<span class="number">1024</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            layers.Dense(<span class="number">128</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Dense(num_classes),</span><br><span class="line">            layers.Softmax()</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># input = tf.random.uniform(shape=(16, 224, 32, 3))</span></span><br><span class="line"><span class="built_in">input</span> = tf.random.uniform(shape=(<span class="number">8</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># alexnet = AlexNet_v2(num_classes=5)</span></span><br><span class="line"><span class="comment"># print(alexnet)</span></span><br><span class="line"><span class="comment"># print(alexnet.call(input))</span></span><br><span class="line">AlexNet_v1(<span class="number">224</span>, <span class="number">224</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;1、AlexNet简介&quot;&gt;&lt;a href=&quot;#1、AlexNet简介&quot; class=&quot;headerlink&quot; title=&quot;1、AlexNet简介&quot;&gt;&lt;/a&gt;1、AlexNet简介&lt;/h4&gt;&lt;p&gt;Alexnet是2012年ILSVRC 2012(ImageNet </summary>
      
    
    
    
    
    <category term="深度学习" scheme="https://guudman.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scipy中常用的数据结构</title>
    <link href="https://guudman.github.io/2023/10/11/scipy%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://guudman.github.io/2023/10/11/scipy%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2023-10-11T07:28:31.000Z</published>
    <updated>2023-10-11T07:31:37.397Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、-scipy中常用的数据结构"><a href="#1、-scipy中常用的数据结构" class="headerlink" title="1、 scipy中常用的数据结构"></a>1、 scipy中常用的数据结构</h3><h4 id="1-1-scipy-sparse-coo-matrix"><a href="#1-1-scipy-sparse-coo-matrix" class="headerlink" title="1.1 scipy.sparse.coo_matrix"></a>1.1 scipy.sparse.coo_matrix</h4><p>coo_matrix全称是A sparse matrix in Coordinate format， 一种基于坐标格式的系数矩阵， 每个矩阵时一个三元组（行， 列， 值）</p><p>构造方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.sparse <span class="keyword">import</span> coo_matrix</span><br><span class="line">coo = coo_matrix(np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>]).reshape(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(coo)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  (0, 0)1</span></span><br><span class="line"><span class="string">  (0, 1)2</span></span><br><span class="line"><span class="string">  (0, 2)3</span></span><br><span class="line"><span class="string">  (1, 0)4</span></span><br><span class="line"><span class="string">  (1, 1)5</span></span><br><span class="line"><span class="string">  (1, 2)6</span></span><br><span class="line"><span class="string">  coo_matrix中值表示非零元素， 如果该位置是0， 则没有改行的数值</span></span><br><span class="line"><span class="string">  如， 当输入的array是[1, 0, 3, 0, 5]</span></span><br><span class="line"><span class="string">  (0, 0)1</span></span><br><span class="line"><span class="string">  (0, 2)3</span></span><br><span class="line"><span class="string">  (1, 1)5</span></span><br><span class="line"><span class="string">  (1, 2)6</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 第二种方法</span></span><br><span class="line">row = np.array([<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">col = np.array([<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">data = np.array([<span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</span><br><span class="line">coo_matrix_1 = coo_matrix((data, (row, col)), shape=(<span class="number">4</span>, <span class="number">4</span>)).toarray()</span><br><span class="line"><span class="built_in">print</span>(coo_matrix_1)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">coo_matrix((data, (i, j)), [shape=(M, N)])</span></span><br><span class="line"><span class="string">data即矩阵存储的数据，i为行下标，j为列下标，</span></span><br><span class="line"><span class="string">data,i,j的关系为：A[i[k], j[k]] = data[k]</span></span><br><span class="line"><span class="string">0行0列是4， 3行3列是5， 以此类推</span></span><br><span class="line"><span class="string">[[4 0 9 0]</span></span><br><span class="line"><span class="string"> [0 7 0 0]</span></span><br><span class="line"><span class="string"> [0 0 0 0]</span></span><br><span class="line"><span class="string"> [0 0 0 5]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h4 id="1-2-scipy-sparse-csr-matrix"><a href="#1-2-scipy-sparse-csr-matrix" class="headerlink" title="1.2 scipy.sparse.csr_matrix"></a>1.2 scipy.sparse.csr_matrix</h4><p>csr是Compressed Sparse Row matrix的缩写， 即基于行存储的压缩稀疏矩阵，</p><p>有几种不同的构造方法， csr_matrix(D), D是一个稠密矩阵或2维的ndarray</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.sparse <span class="keyword">import</span> csr_matrix</span><br><span class="line">csr = csr_matrix(np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]).reshape(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">其实跟coo_matrix很像</span></span><br><span class="line"><span class="string">  (0, 0)1</span></span><br><span class="line"><span class="string">  (0, 1)2</span></span><br><span class="line"><span class="string">  (0, 2)3</span></span><br><span class="line"><span class="string">  (1, 0)4</span></span><br><span class="line"><span class="string">  (1, 1)5</span></span><br><span class="line"><span class="string">  (1, 2)6</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment">#  csr_matrix((M, N), [dtype])构造一个shape为(M, N)的dtype类型的空矩阵</span></span><br><span class="line">csr_matrix_1 = csr_matrix((<span class="number">3</span>, <span class="number">4</span>), dtype=np.int8).toarray()</span><br><span class="line"><span class="built_in">print</span>(csr_matrix_1)</span><br><span class="line"><span class="string">&quot;&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[[0 0 0 0]</span></span><br><span class="line"><span class="string"> [0 0 0 0]</span></span><br><span class="line"><span class="string"> [0 0 0 0]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 这种方法跟coo_matrix中的也是一样的</span></span><br><span class="line">row = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">col = np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">data = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">csr_matrix_2 = csr_matrix((data, (row, col)), shape=(<span class="number">3</span>, <span class="number">3</span>)).toarray()</span><br><span class="line"><span class="built_in">print</span>(csr_matrix_2)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[[1 0 2]</span></span><br><span class="line"><span class="string"> [0 0 3]</span></span><br><span class="line"><span class="string"> [4 5 6]]</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> 按行存储，即先存储第0行，然后第1行，依次到最后一行，即先扫描row数组的数据，第一个数据是0即第0行，然后扫描col的第一个数据是0即第0列，那么第0行第0列存储的值就是data的第一个数据即1，然后继续扫描row的第二个数据还是0即还是第0行，col对应的第二个数据是2即第2列，data的第二个数据是2，即第0行第2列的数据是2，依次扫描row，找对应的col和data构造稀疏矩阵。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1、-scipy中常用的数据结构&quot;&gt;&lt;a href=&quot;#1、-scipy中常用的数据结构&quot; class=&quot;headerlink&quot; title=&quot;1、 scipy中常用的数据结构&quot;&gt;&lt;/a&gt;1、 scipy中常用的数据结构&lt;/h3&gt;&lt;h4 id=&quot;1-1-scipy</summary>
      
    
    
    
    
    <category term="图神经网络" scheme="https://guudman.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>neo4j基本使用</title>
    <link href="https://guudman.github.io/2023/09/11/neo4j%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
    <id>https://guudman.github.io/2023/09/11/neo4j%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</id>
    <published>2023-09-11T11:09:51.000Z</published>
    <updated>2023-09-12T17:33:59.379Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-neo4j数据类型"><a href="#1-neo4j数据类型" class="headerlink" title="1. neo4j数据类型"></a>1. neo4j数据类型</h4><p>1.Node: 节点， 基本语法：Node(*label, **properties)</p><p>第一步：连接neo4j数据库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> py2neo <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://localhost:7474&quot;</span></span><br><span class="line">graph = Graph(url, username=<span class="string">&quot;neo4j&quot;</span>, password=<span class="string">&quot;szyh&quot;</span>)</span><br></pre></td></tr></table></figure><p>第二步：创建节点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立节点</span></span><br><span class="line">node_1 = Node(<span class="string">&quot;英雄&quot;</span>, name=<span class="string">&quot;张无忌&quot;</span>)</span><br><span class="line">node_2 = Node(<span class="string">&quot;英雄&quot;</span>, name=<span class="string">&quot;杨道&quot;</span>, 武力值=<span class="string">&#x27;100&#x27;</span>)</span><br><span class="line">node_3 = Node(<span class="string">&quot;派别&quot;</span>, name=<span class="string">&quot;明教&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存入图数据库</span></span><br><span class="line">graph.create(node_1)</span><br><span class="line">graph.create(node_2)</span><br><span class="line">graph.create(node_3)</span><br><span class="line"><span class="built_in">print</span>(node_1)</span><br></pre></td></tr></table></figure><p><img src="/images/1692668067239-e7227df7-867e-41ad-9cf6-fb6d85176385.png"></p><p>2 relationship关系基本语法： Relationship((start_node, type, end_node, **properties)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加关系</span></span><br><span class="line">node_1_to_node_2 = Relationship(node_1, <span class="string">&#x27;教主&#x27;</span>, node_2)</span><br><span class="line">node_3_to_node_1 = Relationship(node_3, <span class="string">&#x27;统领&#x27;</span>, node_1)</span><br><span class="line">node_2_to_node_3 = Relationship(node_2, <span class="string">&#x27;师出&#x27;</span>, node_3)</span><br><span class="line">graph.create(node_1_to_node_2)</span><br><span class="line">graph.create(node_3_to_node_1)</span><br><span class="line">graph.create(node_2_to_node_3)</span><br></pre></td></tr></table></figure><p><img src="/images/1692668510722-f9833f06-967c-46c2-b96a-691de7332604.png"></p><ol><li>Path路径，基本语法：Path(*entities), 注意entities是实体(关系，节点都可以作为实体)</li></ol><p><img src="/images/1692668994710-e1991773-6b57-4b22-8471-ff8e25e395e5.png" alt="img"></p><ol><li>Subgraph:子图是节点和关系的任意集合，它也是Node, Relationship和Path的基类， 基本语法：Subgraph(nodes, relationships)。 空子图表示为None, 使用bool()可以测试是否为空，参数要按数组输入，如下面代码：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建子图，通过子图的方式更新数据库</span></span><br><span class="line">node_7 = Node(<span class="string">&#x27;英雄&#x27;</span>, name=<span class="string">&#x27;张翠山&#x27;</span>)</span><br><span class="line">node_8 = Node(<span class="string">&#x27;英雄&#x27;</span>, name=<span class="string">&#x27;殷素素&#x27;</span>)</span><br><span class="line">node_9 = Node(<span class="string">&#x27;英雄&#x27;</span>, name=<span class="string">&#x27;狮王&#x27;</span>)</span><br><span class="line"></span><br><span class="line">relationship7 = Relationship(node_1, <span class="string">&#x27;生父&#x27;</span>, node_7)</span><br><span class="line">relationship8 = Relationship(node_1, <span class="string">&#x27;生母&#x27;</span>, node_8)</span><br><span class="line">relationship9 = Relationship(node_1, <span class="string">&#x27;义父&#x27;</span>, node_9)</span><br><span class="line">subgraph_1 = Subgraph(nodes=[node_7, node_8, node_9],</span><br><span class="line">                      relationships=[relationship7, relationship8, relationship9])</span><br><span class="line">graph.create(subgraph_1)</span><br></pre></td></tr></table></figure><p><img src="/images/1692669527475-c9d0a0dc-9d4d-4ffd-98ed-a9afeb17a4b5.png"></p><p>工作流</p><ol><li>GraphService: 基于图服务的工作流</li><li>Graph: 基于图数据库的工作流</li><li>Transaction: 基于事务的工作流，一个Transaction分两个任务，增加一个新节点，将该节点与已有节点创建新关系。这两个任务有一个没完成，整个工作流就不会生效。通常，这种方式通过Graph.begin(readonly&#x3D;False)构造函数构造，参数readonly表示只读</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个新事务</span></span><br><span class="line">transcation_1 = graph.begin()</span><br><span class="line"><span class="comment"># 创建一个新Node</span></span><br><span class="line">node_10 = Node(<span class="string">&#x27;武当&#x27;</span>, name=<span class="string">&#x27;张三丰&#x27;</span>)</span><br><span class="line">transcation_1.create(node_10)</span><br><span class="line"><span class="comment"># 创建两个关系: 张无忌-&gt;(师公)-&gt;张三丰 张翠山-&gt;(妻子)-&gt;殷素素</span></span><br><span class="line">relationship10 = Relationship(node_1, <span class="string">&#x27;师公&#x27;</span>, node_10)</span><br><span class="line">relationship11 = Relationship(node_7, <span class="string">&#x27;妻子&#x27;</span>, node_8)</span><br><span class="line">transcation_1.create(relationship10)</span><br><span class="line">transcation_1.create(relationship11)</span><br><span class="line">transcation_1.commit()</span><br></pre></td></tr></table></figure><p>一个transaction增加的一个节点和两个关系</p><p><img src="/images/1692670406583-378901a5-73a1-4897-b269-2913bec75ad8.png"></p><p>删</p><ol><li>删除数据库中所有的节点和关系: graph.delete_all()</li><li>其他删除方法如下(删除的基础是查询，但凡查询条件没错，就不会删错)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除所有，</span></span><br><span class="line"><span class="comment"># graph.delete_all()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照id删除，要删除节点前，首先需删除关系，否则会报错:ClientError</span></span><br><span class="line"><span class="comment"># graph.run(&#x27;math (r) where id(r) = 3 delete r&#x27;)</span></span><br><span class="line"><span class="comment"># 按照name属性删除，先增加一个独立的节点</span></span><br><span class="line">node_x = Node(<span class="string">&#x27;英雄&#x27;</span>, name=<span class="string">&#x27;韦一笑&#x27;</span>)</span><br><span class="line"><span class="comment"># graph.create(node_x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># graph.run(&#x27;match (n:英雄&#123;name:\&#x27;韦一笑\&#x27;&#125;) delete n&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除一个节点及与之相连的关系</span></span><br><span class="line"><span class="comment"># graph.run(&#x27;match (n:英雄&#123;name:\&#x27;韦一笑\&#x27;&#125;) detach delete n&#x27;)</span></span><br><span class="line"><span class="comment"># 删除某一类型的关系</span></span><br><span class="line">graph.run(<span class="string">&#x27;match ()-[r:喜欢]-&gt;() delete r;&#x27;</span>)</span><br><span class="line"><span class="comment"># 删除子图</span></span><br><span class="line"><span class="comment"># delete(subgraph_1)</span></span><br></pre></td></tr></table></figure><p>改</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 改</span><br><span class="line"># 将狮王的武力值改为100</span><br><span class="line">node_9[&#x27;武力值&#x27;]=100</span><br><span class="line"># 本地修改完，要push到服务器上哦</span><br><span class="line">test_graph.push(node_9)</span><br></pre></td></tr></table></figure><p>查询</p><p>查询，按照路径、节点、关系等查询</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了方便查询更多内容，新增一些关系和节点</span></span><br><span class="line">transcation_2 = graph.begin()</span><br><span class="line">node_100 = Node(<span class="string">&#x27;巾帼&#x27;</span>, name=<span class="string">&#x27;赵敏&#x27;</span>)</span><br><span class="line">re_100 = Relationship(node_1, <span class="string">&#x27;Love&#x27;</span>, node_100)</span><br><span class="line"></span><br><span class="line">node_101 = Node(<span class="string">&#x27;巾帼&#x27;</span>, name=<span class="string">&#x27;周芷若&#x27;</span>)</span><br><span class="line">re_101 = Relationship(node_1, <span class="string">&#x27;knows&#x27;</span>, node_101)</span><br><span class="line">re_101_ = Relationship(node_101, <span class="string">&#x27;hate&#x27;</span>, node_100)</span><br><span class="line"></span><br><span class="line">node_102 = Node(<span class="string">&#x27;巾帼&#x27;</span>, name=<span class="string">&#x27;小昭&#x27;</span>)</span><br><span class="line">re_102 = Relationship(node_1, <span class="string">&#x27;knows&#x27;</span>, node_102)</span><br><span class="line"></span><br><span class="line">node_103 = Node(<span class="string">&#x27;巾帼&#x27;</span>, name=<span class="string">&#x27;蛛儿&#x27;</span>)</span><br><span class="line">re_103 = Relationship(node_103, <span class="string">&#x27;Love&#x27;</span>, node_1)</span><br><span class="line">transcation_2.create(node_100)</span><br><span class="line">transcation_2.create(re_100)</span><br><span class="line"></span><br><span class="line">transcation_2.create(node_101)</span><br><span class="line">transcation_2.create(re_101)</span><br><span class="line">transcation_2.create(re_101_)</span><br><span class="line"></span><br><span class="line">transcation_2.create(node_102)</span><br><span class="line">transcation_2.create(re_102)</span><br><span class="line"></span><br><span class="line">transcation_2.create(node_103)</span><br><span class="line">transcation_2.create(re_103)</span><br><span class="line">transcation_2.commit()</span><br></pre></td></tr></table></figure><p><img src="/images/1692672097202-eba07f27-1ef1-4c02-87ee-4c00d87b949d.png"></p><p>NodeMatcher: 定位满足特定条件的节点，基本语法：NodeMatcher(graph).match(*labels, **properties)， </p><table><thead><tr><th>方法名</th><th>功能</th></tr></thead><tbody><tr><td>first(）</td><td>返回查询结果第一个Node, 没有则返回空</td></tr><tr><td>where(conditino,properties)</td><td>过滤查询结果</td></tr><tr><td>order_by</td><td>排序</td></tr></tbody></table><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 定义查询</span><br><span class="line">node_match = NodeMatcher(graph)</span><br><span class="line"># # 单个节点， 按照label和name查询</span><br><span class="line">node_single = node_match.match(&#x27;英雄&#x27;, name=&#x27;杨逍&#x27;).first()</span><br><span class="line">print(&quot;单节点查询:&quot;, node_single)</span><br><span class="line"></span><br><span class="line"># # 按label查询</span><br><span class="line"># node_hero = list(node_match.match(&#x27;英雄&#x27;).all())</span><br><span class="line"># print(&quot;查询结果类型&quot;, type(node_hero))</span><br><span class="line">node_hero = node_match.match(&#x27;英雄&#x27;).__iter__()</span><br><span class="line"></span><br><span class="line"># 循环取值</span><br><span class="line">i = 0</span><br><span class="line">for node in node_hero:</span><br><span class="line">    print(&quot;label查询第&#123;&#125;个为&#123;&#125;&quot;.format(i, node))</span><br><span class="line">    i += 1</span><br><span class="line"></span><br><span class="line"># 按照name查询</span><br><span class="line">node_name = node_match.match(name=&#x27;张无忌&#x27;)</span><br><span class="line">print(&quot;name查询结果&quot;, node_name)</span><br><span class="line"></span><br><span class="line"># 按照id查询</span><br><span class="line">node_id = node_match.get(1)</span><br><span class="line">print(&quot;id查询结果&quot;, node_id)</span><br></pre></td></tr></table></figure><ol><li>NodeMatch， 基本用法， NodeMatch(graph, labels&#x3D;frozenset({}), predicates&#x3D;(), order_by&#x3D;(), skip&#x3D;None, limit&#x3D;None)可以看出，NodeMatcher与NodeMatch参数完全不同，后面可以加很多条件</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">node_match1 = NodeMatch(graph, labels=<span class="built_in">frozenset</span>(&#123;<span class="string">&#x27;英雄&#x27;</span>&#125;))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>,<span class="string">&#x27;遍历所有节点&#x27;</span>, <span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>)</span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> <span class="built_in">iter</span>(node_match1):</span><br><span class="line">    <span class="built_in">print</span>(node)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>,<span class="string">&#x27;查询结果计数&#x27;</span>, <span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>)</span><br><span class="line"><span class="built_in">print</span>(node_match1.__len__())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照武力值排序查询结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>,<span class="string">&#x27;按照武力值排序查询结果&#x27;</span>, <span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>)</span><br><span class="line">wu = node_match1.order_by(<span class="string">&#x27;_.武力值&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> wu:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line">=============== 遍历所有节点 ===============</span><br><span class="line">(_3104:英雄 &#123;name: <span class="string">&#x27;\u6768\u9053&#x27;</span>, 武力值: <span class="string">&#x27;100&#x27;</span>&#125;)</span><br><span class="line">(_3257:英雄 &#123;name: <span class="string">&#x27;\u5f20\u65e0\u5fcc&#x27;</span>&#125;)</span><br><span class="line">(_4209:英雄 &#123;name: <span class="string">&#x27;\u5f20\u7fe0\u5c71&#x27;</span>&#125;)</span><br><span class="line">(_4210:英雄 &#123;name: <span class="string">&#x27;\u72ee\u738b&#x27;</span>, 武力值: <span class="number">10</span>&#125;)</span><br><span class="line">(_4211:英雄 &#123;name: <span class="string">&#x27;\u6bb7\u7d20\u7d20&#x27;</span>&#125;)</span><br><span class="line">=============== 查询结果计数 ===============</span><br><span class="line"><span class="number">5</span></span><br><span class="line">=============== 按照武力值排序查询结果 ===============</span><br><span class="line">(_3104:英雄 &#123;name: <span class="string">&#x27;\u6768\u9053&#x27;</span>, 武力值: <span class="string">&#x27;100&#x27;</span>&#125;)</span><br><span class="line">(_4210:英雄 &#123;name: <span class="string">&#x27;\u72ee\u738b&#x27;</span>, 武力值: <span class="number">10</span>&#125;)</span><br><span class="line">(_3257:英雄 &#123;name: <span class="string">&#x27;\u5f20\u65e0\u5fcc&#x27;</span>&#125;)</span><br><span class="line">(_4209:英雄 &#123;name: <span class="string">&#x27;\u5f20\u7fe0\u5c71&#x27;</span>&#125;)</span><br><span class="line">(_4211:英雄 &#123;name: <span class="string">&#x27;\u6bb7\u7d20\u7d20&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure><ol><li>RelationshipMatcher:用于选择满足一组特定标准的关系的匹配器，基础语法，relation&#x3D;RelationshipMatcher(graph)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">relation = RelationshipMatcher(graph)</span><br><span class="line"><span class="comment"># Node表示any node</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>,<span class="string">&#x27;hate关系查询&#x27;</span>, <span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>)</span><br><span class="line">x = relation.<span class="keyword">match</span>(nodes=<span class="literal">None</span>, r_type=<span class="string">&#x27;hate&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> x_ <span class="keyword">in</span> x:</span><br><span class="line">    <span class="built_in">print</span>(x_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加两关系</span></span><br><span class="line">rel_1 = Relationship(node_101, <span class="string">&#x27;情敌&#x27;</span>, node_102)</span><br><span class="line">rel_2 = Relationship(node_102, <span class="string">&#x27;情敌&#x27;</span>, node_103)</span><br><span class="line">graph.create(rel_1)</span><br><span class="line">graph.create(rel_2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 情敌查询结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>,<span class="string">&#x27;hate关系查询结果&#x27;</span>, <span class="string">&#x27;=&#x27;</span>*<span class="number">15</span>)</span><br><span class="line">x = relation.<span class="keyword">match</span>(nodes=<span class="literal">None</span>, r_type=<span class="string">&#x27;情敌&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> x_ <span class="keyword">in</span> x:</span><br><span class="line">    <span class="built_in">print</span>(x_)</span><br><span class="line">=============== hate关系查询 ===============</span><br><span class="line">(周芷若)-[:hate &#123;&#125;]-&gt;(赵敏)</span><br><span class="line">=============== hate关系查询结果 ===============</span><br><span class="line">(小昭)-[:情敌 &#123;&#125;]-&gt;(蛛儿)</span><br><span class="line">(周芷若)-[:情敌 &#123;&#125;]-&gt;(小昭)</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;1-neo4j数据类型&quot;&gt;&lt;a href=&quot;#1-neo4j数据类型&quot; class=&quot;headerlink&quot; title=&quot;1. neo4j数据类型&quot;&gt;&lt;/a&gt;1. neo4j数据类型&lt;/h4&gt;&lt;p&gt;1.Node: 节点， 基本语法：Node(*label, **</summary>
      
    
    
    
    
    <category term="neo4j" scheme="https://guudman.github.io/tags/neo4j/"/>
    
  </entry>
  
  <entry>
    <title>关于我</title>
    <link href="https://guudman.github.io/2023/09/09/%E5%85%B3%E4%BA%8E%E6%88%91/"/>
    <id>https://guudman.github.io/2023/09/09/%E5%85%B3%E4%BA%8E%E6%88%91/</id>
    <published>2023-09-09T07:55:49.000Z</published>
    <updated>2023-09-12T17:44:28.195Z</updated>
    
    <content type="html"><![CDATA[<h2 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h2><p>。。。待更新</p><h2 id="后续计划"><a href="#后续计划" class="headerlink" title="后续计划"></a>后续计划</h2><p>* </p><p>* </p><h2 id="希望你的加入"><a href="#希望你的加入" class="headerlink" title="希望你的加入"></a>希望你的加入</h2><p>* </p><p>* </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;自我介绍&quot;&gt;&lt;a href=&quot;#自我介绍&quot; class=&quot;headerlink&quot; title=&quot;自我介绍&quot;&gt;&lt;/a&gt;自我介绍&lt;/h2&gt;&lt;p&gt;。。。待更新&lt;/p&gt;
&lt;h2 id=&quot;后续计划&quot;&gt;&lt;a href=&quot;#后续计划&quot; class=&quot;headerlink&quot; ti</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>欢迎来到我的世界</title>
    <link href="https://guudman.github.io/2023/09/08/%E4%B8%96%E7%95%8C%EF%BC%8C%E4%BD%A0%E5%A5%BD/"/>
    <id>https://guudman.github.io/2023/09/08/%E4%B8%96%E7%95%8C%EF%BC%8C%E4%BD%A0%E5%A5%BD/</id>
    <published>2023-09-08T08:39:39.830Z</published>
    <updated>2023-09-12T17:44:04.117Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#</summary>
      
    
    
    
    
  </entry>
  
</feed>
