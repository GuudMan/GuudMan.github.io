<!DOCTYPE html><html lang="zh-cn" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Ai4Future</title><meta name="keywords" content="成长，分享，专注"><meta name="author" content="AI4Future"><meta name="copyright" content="AI4Future"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Not Only Look Once">
<meta property="og:type" content="website">
<meta property="og:title" content="Ai4Future">
<meta property="og:url" content="https://guudman.github.io/index.html">
<meta property="og:site_name" content="Ai4Future">
<meta property="og:description" content="Not Only Look Once">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://guudman.github.io/img/avatar.jpg">
<meta property="article:author" content="AI4Future">
<meta property="article:tag" content="成长，分享，专注">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://guudman.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://guudman.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":50,"languages":{"author":"Author: AI4Future","link":"Link: ","source":"Source: Ai4Future","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://fastly.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://fastly.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Ai4Future',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-12-08 08:57:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Ai4Future" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="onerror=null;src='https://gitee.com/guudman/blog_images/raw/master/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">AI4Future</div><div class="author-info__description">Not Only Look Once</div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/GuudMan" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2663017379@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-clock"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/gedan"><i class="fa-fw fas fa-music"></i><span> 歌单</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk"><i class="fa-fw fa fa-heartbeat"></i><span> 时光</span></a></div><div class="menus_item"><a class="site-page" href="/shuoba"><i class="fa-fw fas fa-comment-dots"></i><span> 说吧</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/google"><span> 镜像</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://json.xbyzs.cf"><span> Json格式化</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://draw.xbyzs.cf"><span> Draw画布</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://enkey.xbyzs.cf"><span> EnKey</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ai4Future</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-clock"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/gedan"><i class="fa-fw fas fa-music"></i><span> 歌单</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk"><i class="fa-fw fa fa-heartbeat"></i><span> 时光</span></a></div><div class="menus_item"><a class="site-page" href="/shuoba"><i class="fa-fw fas fa-comment-dots"></i><span> 说吧</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/google"><span> 镜像</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://json.xbyzs.cf"><span> Json格式化</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://draw.xbyzs.cf"><span> Draw画布</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://enkey.xbyzs.cf"><span> EnKey</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/12/08/Self-Attention/" title="Self_Attention">Self_Attention</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-12-08T00:56:46.000Z" title="Created 2023-12-08 08:56:46">2023-12-08</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-12-08T00:57:22.420Z" title="Updated 2023-12-08 08:57:22">2023-12-08</time></span></div><div class="content">

1、简介seq2seq模型有两个RNN网络， 一个encoder， 一个decoder。这里介绍self-attention， 把attention用在一个RNN网络上。
attention的第一篇文章发表在2015年， 用来改进seq2seq模型， 解决RNN的遗忘问题。其实attention并不局限于seq2seq模型， attention可以用在所有的RNN上。下面介绍Self-Attention， 文章发表在2016年， 比第一篇attention论文晚一年。
Self-Attention的原始论文把attention用在LSTM上， 把它们的论文做了简化。为了方便理解， 把LSTM换成simple RNN。
现在开始simple RNN与Self-Attention的结合，初始的时候状态向量h与context vector c都是全零向量。

RNN读入第一个输出x1， 需要更新状态h。把x1的信息压缩到新的状态h里面。标准的simple RNN是这样计算状态h1的。新的状态h1依赖于旧的状态h0与新的输入x1。

上面的公式中， 新的输入x1与旧的状态h做concati ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/12/07/Attention/" title="Attention">Attention</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-12-07T11:48:39.000Z" title="Created 2023-12-07 19:48:39">2023-12-07</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-12-07T11:49:41.568Z" title="Updated 2023-12-07 19:49:41">2023-12-07</time></span></div><div class="content">

1、简介先回顾seq2seq模型， seq2seq模型有一个encoder和一个decoder。encoder的输入是英语， decoder把英语翻译成德语。encoder每次读入一个英语向量x， 在状态h中积累输入的信息。最后一个状态hm中积累了所有词向量x的信息。encoder输出最后ig状态hm， 把之前的状态向量全部扔掉。

decoder RNN的初始状态s0等于encoder RNN的最后一个状态hm。hm包含了输入英语句子的信息， 通过hm， decoder就知道了这句英语。然后decoder就像文本生成器一样， 逐字生成一句德语。这句德语就是模型生成的翻译。

但seq2seq模型有一个明显的缺陷， 就是如果输入的句子很长， 那么encoder会记不住完整的句子。encoder最后一个状态可能会漏掉一些信息。假如输入的英语里有个别词被忘记了， 那么decoder就无从得知完整的句子， 也就不可能产生正确的翻译。
如果你拿seq2seq模型做机器翻译， 你会得到这样的结果。 横轴是输入句子的长度。纵轴是BLEU， BLEU score是评价机器翻译好坏的标准。BLEU ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/12/07/Seq2Seq/" title="Seq2Seq">Seq2Seq</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-12-07T11:32:24.000Z" title="Created 2023-12-07 19:32:24">2023-12-07</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-12-07T11:33:34.952Z" title="Updated 2023-12-07 19:33:34">2023-12-07</time></span></div><div class="content">

1、简介使用RNN来做机器翻译， 机器翻译模型有很多种， 这里介绍sequence-2-sequence模型， 机器翻译是many-2-many多对多的问题。输入的英语长度大于1， 输出的德语长度也大于1，而且输入和输出的长度不固定。

做任何机器学习的应用， 第一步都是处理输出。这里就取一个小规模数据集就行。可用该网站英语翻译语料 (manythings.org)](http://www.manythings.org/anki/))提供的小规模数据集来训练一个seq-2-seq模型。这个网站上有多种语言翻译的数据， 这个文件是德语和英语的翻译。文件中， 坐标是英语句子， 右边是德语句子， 给定一句英语， 如何翻译结果呢， match其中一个德语句子就算完全正确。

处理数据时， 把这些句子用矩阵表示， 首先做预处理， 比如把大小变成小写， 去掉标点符号。
处理之后就要做tokenization， 把一句话变成很多个单词或者字符。做tokenization时， 要用两个不同的tokenizer， 英语用一个， 德语用一个。tokenization之后要建立两个字典， 一个英语字典， ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/12/03/TextGeneration/" title="TextGeneration">TextGeneration</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-12-03T06:53:05.000Z" title="Created 2023-12-03 14:53:05">2023-12-03</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-12-03T06:55:36.238Z" title="Updated 2023-12-03 14:55:36">2023-12-03</time></span></div><div class="content">

1、简介可以训练一个RNN， 它它自动生成文本， 生成的文本就像人写的一样。如果用莎士比亚的书来训练RNN， 生成的文本就像莎士比亚写的一样， 举个例子来解释文本生成。
输入本句话the cat sat on the ma, 要求训练一个神经网络来预测下一个字符。训练数据是很多文本， 把文本分割成字符， 用one-hot encoding来表示字符，这样每个字符就表示成一个one hot向量。把这些one-hot向量依次输入到RNN， RNN的状态向量h会积累看到的信息， RNN返回最后一个状态向量h。RNN层上面是一个softmax分类器， 把h与参数矩阵w相乘， 得到一个向量，经过softmax函数的变换， 最终输出是一个向量。向量每个元素都在0~1之间，元素全加起来等于1， softmax分类器的输出其实就是一个概率分布。

假设这个神经网络已经训练好了， 我们把the cat sat on the mat输入到这个神经网络中， 神经网络最上层softmax分类器会输出这些概率值。每个字符对应一个概率值， 其中概率最大的是字符t， 大小约为0.175。有了这些概率值， 我们就 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/12/02/make-RNN-more-efficient/" title="make_RNN_more_efficient">make_RNN_more_efficient</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-12-02T07:56:23.000Z" title="Created 2023-12-02 15:56:23">2023-12-02</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-12-02T08:22:40.189Z" title="Updated 2023-12-02 16:22:40">2023-12-02</time></span></div><div class="content">

1、stacked RNN3个技巧提升RNN的效果。
第一个是Stacked RNN。stack RNN为多层RNN， 可以把很多全连接层堆叠起来， 构成一个multilayer percepter， 也可把很多卷积层堆叠起来， 构成一个深度卷积网络。同样的道理也可以把很多RNN堆叠起来构成一个多层RNN网络。神经网络的每一步都会更新状态h， 新算出来的h有两个copy， 一份送到下一个时刻， 另外一份作为输出。这一层输出的状态h成为了上一层的输入。再解释一下， 最底层的RNN的输入是词向量x， 这层RNN会输出每一步的状态向量h， 这些输出的状态向量又成为了第二次RNN的输入。

第二次RNN有自己的模型参数， 会更新和输出自己的状态向量h， 第二层输出的状态向量h又成为了第三层RNN的输入。

一共有三层RNN， 最上层的状态向量是最终的输出， 可以用最后一个状态ht看成是从最底层的输入I love the movie so much中提取的特征向量。
使用keras实现多层LSTM， 这里用了三层LSTM层。第一层的输出会成为第二层的输入， 所以第一层的return_sequ ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/12/02/LSTM/" title="LSTM">LSTM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-12-02T07:49:02.000Z" title="Created 2023-12-02 15:49:02">2023-12-02</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-12-02T08:23:08.762Z" title="Updated 2023-12-02 16:23:08">2023-12-02</time></span></div><div class="content">

1、简介LSTM是一种RNN模型， 是对Simple RNN的改进， LSTM可以避免梯度消失的问题， 可以有更长的记忆。原论文 Long Short-term Memory (researchgate.net)](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory))是1997年发表的。下图是LSTM原论文中的截取的图。

LSTM也是一种循环神经网络， 原理跟Simple RNN差不多。

每当读取一个新的输入x就会更新状态h， lstm的结构比simple RNN要复杂很多。Simple RNN只有一个参数矩阵， LSTM有4个参数矩阵， 下面看一下LSTM内部的具体结构。
2、LSTM结构LSTM最重要的设计是这个传输带， 即为向量C。过去的信息通过传输带送到下一个时刻，不会发生太大的变化， LSTM就是通过传输传输带来避免梯度消失。

LSTM中有很多gate可以有选择的让信息通过， 先来看一下forget gate遗忘门。遗忘门由sigmoid function和Element ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/12/01/RNN/" title="RNN">RNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-12-01T09:50:00.000Z" title="Created 2023-12-01 17:50:00">2023-12-01</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-12-01T10:04:34.438Z" title="Updated 2023-12-01 18:04:34">2023-12-01</time></span></div><div class="content">

1、简介RNN循环神经网络在nlp领域有些过时了， 训练数据足够多时， RNN的效果不如transformers模型， 但在小规模问题上， RNN还是很有用。机器学习中经常用到的文本、语音等时序数据， 思考一下， 如何对时序数据建模。在上面的基础部分讲到把一段文字整体输入到一个logistics regression模型， 让模型做二分类， 这属于one-to-one模型。 一个输入对应一个输出， 全连接神经网络和卷积网络都是one-to-one模型，但人类并不会把一整段文字全部输入到大脑中。 人类阅读时会从左到右阅读一段文字， 阅读时逐渐在大脑中积累文本的信息， 阅读一段话后脑中积累了整段文字的大意。one-to-one模型要求一个输入对应一个输出， 比如输入一张图片， 输出每一类的概率值。one-to-one模型很适合图片的问题， 但不太适合文本的问题。
对于文本问题， 输入和输出长度并不固定。 一句话可长可短， 所以输入的长度并不固定， 输出的长度也不固定。 比如把英文翻译成汉语， 英语可能有10个单词， 但翻译成的汉语可能有10个也可能有8个， 输出汉语的字数并不固定。由于 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/29/NlpFoundation/" title="NlpFoundation">NlpFoundation</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-29T10:03:47.000Z" title="Created 2023-11-29 18:03:47">2023-11-29</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:14:36.133Z" title="Updated 2023-11-29 18:14:36">2023-11-29</time></span></div><div class="content">

1、基础如何将计算机不认识的文本特征转化为数字特征
常见的特征分类有类别特征（categorical feature）和数值特征（numeric feature）。 类别特征一般是有限集合， 没有大小之分， 是并列权重。数值特征如：年龄， 工资等， 有数值大小之分。计算机只能处理数值型特征，因此需要将非数值特征转化为计算机能识别的数字， 如下表中的gender和nationality。gender为二元特征， nationality为多元的类别特征。

国籍表示成1-197之间的整数(全球大概有197个国家)， 但这些整数只是一个类别， 它们之间无法比较大小， 因为这些整数只是类别而已， 并不是真正的数值， 所以需要对国籍做one-hot Embedding。需要注意的是我们这里用数字表示的类别特征从1开始， 因为0要用来保留未知或缺失的国籍，数据库中经常会有缺失数据， 这些缺失的国籍就用0来表示。
对于性别， 用0表示女性， 1表示男性。

上面提到， 1-197只代表一个类别， 它们之间无大小之分， 因此需要对国籍进一步做one-hot Embedding。
类别特征转化数字流 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/27/RepVGG/" title="RepVGG">RepVGG</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-27T10:55:52.000Z" title="Created 2023-11-27 18:55:52">2023-11-27</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:05:56.537Z" title="Updated 2023-11-29 18:05:56">2023-11-29</time></span></div><div class="content">

简介VGG网络是2014年牛津大学提出的， 在2014到2016年， VGG网络可以说是当时很火并广泛应用的backbone， 后面由于新网络的提出， 精度上VGG比不上ResNet， 速度和参数数量VGG比不过MobileNet等轻量级网络， 慢慢的VGG开始淡出人们的视线， 当VGG已经被大家遗忘时， 2021年清华，旷视等机构共同基础了RepVGG网络。
论文中， 作者提到了structural re-parameterization technique方法，即结构重参数化。实际上就是在训练时， 使用一个类似ResNet-style的多分支模型，而推理时转化成VGG-style的单路模型。 如下图， B表示RepVGG训练时采用的网络结构， 而在推理时采用图（C)的网络结构。


RepVGG Block详解其实关于RepVGG模型就是在不断堆叠Rep VGG Block。下面介绍一下RepVGG Blocks中的结构， 如下图针对训练时采用的RepVGG Block结构。其中（a)是进行下采样stride=2时使用的RepVGG Block结构，图(b)是正常的(strid ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/24/YOLOX/" title="YOLOX">YOLOX</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-24T09:55:08.000Z" title="Created 2023-11-24 17:55:08">2023-11-24</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-29T10:06:41.100Z" title="Updated 2023-11-29 18:06:41">2023-11-29</time></span></div><div class="content">

简介前面讲介绍过yolov5， 这里再来介绍YOLOX, YOLOx是旷视科技在2021年发表的一篇论文， 当时对标的网络就是YOLOv5。YOLOx从YOLOv5中引入如下三点：decoupled head, anchor-free以及advanceed label assigning strategy（SimOTA)。
在自己的项目中YOLOv5和YOLOx到底如何选择呢， 如果你的数据集分辨率不是很高， 比如640x640， 二者都可以试试， 如果你的图像分辨率很高， 比如1280x1280， 那么建议使用yolov5， 因为yolov5官方仓库提供了更大尺度的预训练权重， 而YOLOx当前只有640x640的预训练权重。 


网络结构下图是根据源码绘制的YOLOX-L网络结构， 因为它是基于YOLO v5构建的， 所以Backbone以及PAN部分和YOLO v5是一模一样的， 注意这里说的YOLO v5对应的是tag：v5.0版本， 而我们之前的yolov5对应的是tag:v6.1版本， 所以在backbone部分有细微区别。

yolox与yolo v5在结构上有什么 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/#content-inner">4</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='https://gitee.com/guudman/blog_images/raw/master/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">AI4Future</div><div class="author-info__description">Not Only Look Once</div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/GuudMan" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2663017379@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">微信公众号: AI4Future</div></div><div class="sticky_layout"><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">36</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div></div></div></div></div></main><footer id="footer" style="background: #FFFFFF"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By AI4Future</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/chenxz21/hexo-theme-bcxm">Bcxm</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://fastly.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script type="text/javascript" src="https://fastly.jsdelivr.net/npm/leancloud-storage@4.10.0/dist/av-min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>